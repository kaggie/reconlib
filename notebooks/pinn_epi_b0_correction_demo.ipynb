{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Network (PINN) for B0 Off-Resonance Correction in EPI\n",
    "\n",
    "This notebook demonstrates a simplified example of using a Physics-Informed Neural Network (PINN) to correct for B0 off-resonance artifacts in Echo-Planar Imaging (EPI).\n",
    "\n",
    "**MRI Off-Resonance Artifacts in EPI:**\n",
    "EPI is a fast MRI acquisition technique, but it's highly sensitive to magnetic field inhomogeneities (Î”B0). These inhomogeneities cause phase errors during the long EPI readouts, leading to geometric distortions (warping, stretching, signal pile-up/loss) in the reconstructed image, particularly in the phase-encoding direction.\n",
    "\n",
    "**PINN Approach:**\n",
    "A PINN attempts to solve inverse problems by incorporating known physics into the neural network's loss function. For B0 correction, the PINN can:\n",
    "1. Use a neural network (e.g., a CNN) to represent the 'corrected' image.\n",
    "2. Include a data fidelity term that ensures the network output, when transformed by the imaging operator (NUFFT with the actual k-space trajectory), matches the acquired k-space data.\n",
    "3. Add physics-based loss terms that penalize solutions inconsistent with known physics. For B0 off-resonance, this involves using the B0 map to model expected phase distortions. The `B0OffResonanceLoss` term (currently a placeholder) would aim to quantify this inconsistency.\n",
    "\n",
    "This demo uses placeholder physics models for simplicity and speed, but illustrates the overall framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to sys.path to ensure reconlib can be found\n",
    "# Assumes this notebook is in notebooks/ and project root is one level up.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..')) # Use os.getcwd() for notebooks\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- Configuration for Fast Demo Mode ---\n",
    "FAST_DEMO_MODE = True\n",
    "# If True, uses placeholder NUFFT ops defined locally for speed.\n",
    "# If False, attempts to use reconlib.nufft.NUFFT2D.\n",
    "\n",
    "try:\n",
    "    from reconlib.modalities.MRI.pinn_reconstructor import PINNReconstructor, SimpleCNN\n",
    "    from reconlib.nufft import NUFFT2D\n",
    "    from reconlib.nufft_multi_coil import MultiCoilNUFFTOperator\n",
    "    from reconlib.modalities.MRI.physics_loss import PhysicsLossTerm, BlochResidualLoss, GIRFErrorLoss, B0OffResonanceLoss\n",
    "    RECONLIB_AVAILABLE = True\n",
    "    print(\"Successfully imported reconlib modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: Could not import all modules from reconlib. Error: {e}\")\n",
    "    RECONLIB_AVAILABLE = False\n",
    "    if not FAST_DEMO_MODE:\n",
    "        print(\"FATAL: reconlib modules required but not found, and FAST_DEMO_MODE is False. Exiting.\")\n",
    "        # In a notebook, we might not sys.exit, but indicate failure clearly.\n",
    "        raise e\n",
    "\n",
    "# Attempt to import scikit-image for Shepp-Logan phantom\n",
    "try:\n",
    "    from skimage.data import shepp_logan_phantom\n",
    "    from skimage.transform import resize as sk_resize\n",
    "    SKIMAGE_AVAILABLE = True\n",
    "    print(\"Successfully imported scikit-image.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-image not found. Using a simple geometric phantom instead.\")\n",
    "    SKIMAGE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "image_shape_2d = (64, 64)  # Y, X (increased size slightly for better visuals if possible)\n",
    "num_coils = 2\n",
    "num_k_points_epi = image_shape_2d[0] * image_shape_2d[1] # Full sampling for simplicity\n",
    "\n",
    "# EPI Scan Parameters (for B0 loss)\n",
    "scan_parameters_epi = {\n",
    "    'echo_spacing_ms': 0.7,  # Typical echo spacing for EPI\n",
    "    'phase_encoding_lines': image_shape_2d[0], # Ny, number of phase encoding lines\n",
    "}\n",
    "# General Scan Parameters (for Bloch loss, if used)\n",
    "scan_parameters_general = {\"TE\": 0.03, \"TR\": 2.0, \"flip_angle\": 30, \"T1_assumed\": 1.0, \"T2_assumed\": 0.08}\n",
    "\n",
    "pinn_config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"data_fidelity_weight\": 1.0,\n",
    "    \"num_epochs\": 20, # Can be small for demo, increase for better results\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "if FAST_DEMO_MODE:\n",
    "    pinn_config[\"num_epochs\"] = 5 # Even fewer for very fast demo\n",
    "    print(\"FAST_DEMO_MODE: num_epochs reduced to 5.\")\n",
    "\n",
    "# NUFFT parameters (2D)\n",
    "nufft_params_reconlib = {\n",
    "    'oversamp_factor': (1.5, 1.5),\n",
    "    'kb_J': (4, 4),\n",
    "    'Ld': (32, 32) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_tensor, title=\"Image\", cmap=\"gray\", vmin=None, vmax=None, is_complex=True):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    if is_complex:\n",
    "        plot_data = torch.abs(image_tensor.cpu().detach()).numpy()\n",
    "    else:\n",
    "        plot_data = image_tensor.cpu().detach().numpy()\n",
    "    plt.imshow(plot_data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder NUFFT Operators (for FAST_DEMO_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaceholderNUFFT2D:\n",
    "    def __init__(self, image_shape, k_trajectory, device='cpu', **kwargs):\n",
    "        self.image_shape = image_shape\n",
    "        self.k_trajectory = k_trajectory\n",
    "        self.device = device\n",
    "        # print(\"INFO: Using PlaceholderNUFFT2D.\") # Less verbose for notebook\n",
    "\n",
    "    def forward(self, x): # Image (Y,X) -> K-space (K,)\n",
    "        return (torch.sum(x) * 0.0 + torch.zeros(self.k_trajectory.shape[0], dtype=torch.complex64, device=self.device))\n",
    "\n",
    "    def adjoint(self, y): # K-space (K,) -> Image (Y,X)\n",
    "        return (torch.sum(y) * 0.0 + torch.zeros(self.image_shape, dtype=torch.complex64, device=self.device))\n",
    "\n",
    "class PlaceholderMultiCoilNUFFTOperator:\n",
    "    def __init__(self, single_coil_nufft_op):\n",
    "        self.single_coil_nufft_op = single_coil_nufft_op\n",
    "        self.device = single_coil_nufft_op.device\n",
    "        self.image_shape = single_coil_nufft_op.image_shape\n",
    "        # print(\"INFO: Using PlaceholderMultiCoilNUFFTOperator.\")\n",
    "\n",
    "    def op(self, multi_coil_image_data): # (C,Y,X) -> (C,K)\n",
    "        output_kspace_list = []\n",
    "        for i in range(multi_coil_image_data.shape[0]):\n",
    "            single_coil_image = multi_coil_image_data[i]\n",
    "            output_kspace_list.append(self.single_coil_nufft_op.forward(single_coil_image))\n",
    "        return torch.stack(output_kspace_list, dim=0)\n",
    "\n",
    "    def op_adj(self, multi_coil_kspace_data): # (C,K) -> (C,Y,X)\n",
    "        output_image_list = []\n",
    "        for i in range(multi_coil_kspace_data.shape[0]):\n",
    "            single_coil_kspace = multi_coil_kspace_data[i]\n",
    "            output_image_list.append(self.single_coil_nufft_op.adjoint(single_coil_kspace))\n",
    "        return torch.stack(output_image_list, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Phantom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIMAGE_AVAILABLE:\n",
    "    gt_image_np = shepp_logan_phantom()\n",
    "    gt_image_np = sk_resize(gt_image_np, image_shape_2d, anti_aliasing=True)\n",
    "else:\n",
    "    # Simple geometric phantom if scikit-image is not available\n",
    "    gt_image_np = np.zeros(image_shape_2d, dtype=np.float32)\n",
    "    s_y, e_y = image_shape_2d[0]//4, 3*image_shape_2d[0]//4\n",
    "    s_x, e_x = image_shape_2d[1]//4, 3*image_shape_2d[1]//4\n",
    "    gt_image_np[s_y:e_y, s_x:e_x] = 1.0\n",
    "    gt_image_np[s_y+5:e_y-5, s_x+5:e_x-5] = 0.5 # Add some structure\n",
    "\n",
    "gt_image = torch.tensor(gt_image_np, dtype=torch.complex64, device=device)\n",
    "show_image(gt_image, title=\"Ground Truth Phantom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coil Sensitivity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coil_sensitivities = torch.zeros(num_coils, *image_shape_2d, dtype=torch.complex64, device=device)\n",
    "for c in range(num_coils):\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.linspace(-1, 1, image_shape_2d[0], device=device),\n",
    "        torch.linspace(-1, 1, image_shape_2d[1], device=device),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    if c == 0:\n",
    "        coil_sensitivities[c] = (1.0 - 0.8 * torch.abs(xx - 0.3)) * (1.0 - 0.8 * torch.abs(yy - 0.3))\n",
    "    else:\n",
    "        coil_sensitivities[c] = (1.0 - 0.8 * torch.abs(xx + 0.3)) * (1.0 - 0.8 * torch.abs(yy + 0.3))\n",
    "    coil_sensitivities[c] = torch.clamp(coil_sensitivities[c], 0, 1).to(torch.complex64)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_coils, figsize=(5*num_coils, 5))\n",
    "if num_coils ==1 : axes = [axes] # Make iterable if single coil\n",
    "for i in range(num_coils):\n",
    "    axes[i].imshow(torch.abs(coil_sensitivities[i]).cpu().numpy(), cmap='viridis')\n",
    "    axes[i].set_title(f\"Coil {i+1} Sensitivity (Mag)\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B0 Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_freq_max_hz = 30.0  # Max off-resonance in Hz\n",
    "y_coords = torch.linspace(-1, 1, image_shape_2d[0], device=device)\n",
    "x_coords = torch.linspace(-1, 1, image_shape_2d[1], device=device)\n",
    "yy, xx = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "b0_map = b0_freq_max_hz * yy  # Simple linear gradient in y for b0 map\n",
    "b0_map = b0_map.to(device)\n",
    "show_image(b0_map, title=\"B0 Map (Hz)\", cmap='viridis', is_complex=False, vmin=-b0_freq_max_hz, vmax=b0_freq_max_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-space Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_ideal = (torch.rand(num_k_points_epi, 2, device=device) - 0.5).float()\n",
    "\n",
    "off_resonance_factor = 0.05 # Simulates slight distortion for GIRF placeholder\n",
    "trajectory_actual = trajectory_ideal.clone()\n",
    "trajectory_actual[:, 0] += off_resonance_factor * trajectory_ideal[:, 1]\n",
    "trajectory_actual = torch.clamp(trajectory_actual, -0.5, 0.5)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(trajectory_ideal[:,1].cpu().numpy(), trajectory_ideal[:,0].cpu().numpy(), s=1, label='Ideal Traj.')\n",
    "plt.scatter(trajectory_actual[:,1].cpu().numpy(), trajectory_actual[:,0].cpu().numpy(), s=1, label='Actual Traj.', alpha=0.5)\n",
    "plt.xlabel('kx'); plt.ylabel('ky'); plt.title('K-space Trajectories'); plt.legend(); plt.axis('square');\n",
    "plt.xlim([-0.6, 0.6]); plt.ylim([-0.6, 0.6]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Off-Resonant K-space Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified effective TE for phase simulation on image\n",
    "effective_te_for_simulation_s = (scan_parameters_epi['echo_spacing_ms'] / 1000.0) * \\\n",
    "                                (scan_parameters_epi['phase_encoding_lines'] / 2.0)\n",
    "\n",
    "phase_shift = 2 * torch.pi * b0_map * effective_te_for_simulation_s\n",
    "gt_image_offresonant = gt_image * torch.exp(1j * phase_shift)\n",
    "show_image(gt_image_offresonant, title=\"Ground Truth with B0 Phase (Off-Resonant)\")\n",
    "\n",
    "gt_coil_images_offresonant = gt_image_offresonant.unsqueeze(0) * coil_sensitivities\n",
    "\n",
    "# NUFFT operator for simulation (using ideal trajectory for simplicity here)\n",
    "if not FAST_DEMO_MODE and RECONLIB_AVAILABLE:\n",
    "    nufft_sim_single_coil = NUFFT2D(\n",
    "        image_shape=image_shape_2d,\n",
    "        k_trajectory=trajectory_ideal, \n",
    "        device=device,\n",
    "        **nufft_params_reconlib\n",
    "    )\n",
    "    class ReconlibNUFFT2DAdapter:\n",
    "        def __init__(self, nufft2d_instance: NUFFT2D):\n",
    "            self.nufft_instance = nufft2d_instance; self.device = nufft2d_instance.device\n",
    "            self.image_shape = nufft2d_instance.image_shape; self.k_trajectory = nufft2d_instance.k_trajectory\n",
    "        def op(self, x): return self.nufft_instance.forward(x)\n",
    "        def op_adj(self, y): return self.nufft_instance.adjoint(y)\n",
    "    adapter_for_simulation = ReconlibNUFFT2DAdapter(nufft_sim_single_coil)\n",
    "    mc_nufft_for_simulation = MultiCoilNUFFTOperator(adapter_for_simulation)\n",
    "    print(\"INFO: Using reconlib.NUFFT2D for k-space simulation.\")\n",
    "else:\n",
    "    nufft_sim_single_coil = PlaceholderNUFFT2D(image_shape_2d, trajectory_ideal, device)\n",
    "    mc_nufft_for_simulation = PlaceholderMultiCoilNUFFTOperator(nufft_sim_single_coil)\n",
    "    print(\"INFO: Using PlaceholderNUFFT for k-space simulation.\")\n",
    "\n",
    "true_kspace_data_mc = mc_nufft_for_simulation.op(gt_coil_images_offresonant)\n",
    "print(f\"Simulated multi-coil k-space data shape: {true_kspace_data_mc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Image (Adjoint NUFFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjoint NUFFT of the (potentially off-resonant) k-space data\n",
    "# This uses the 'actual' trajectory because that's what the measurements correspond to.\n",
    "if not FAST_DEMO_MODE and RECONLIB_AVAILABLE:\n",
    "    nufft_adj_single_coil = NUFFT2D(image_shape_2d, trajectory_actual, device, **nufft_params_reconlib) # Use actual for adjoint\n",
    "    adapter_adj = ReconlibNUFFT2DAdapter(nufft_adj_single_coil)\n",
    "    mc_nufft_for_adjoint = MultiCoilNUFFTOperator(adapter_adj)\n",
    "    print(\"INFO: Using reconlib.NUFFT2D for initial adjoint image.\")\n",
    "else:\n",
    "    nufft_adj_single_coil = PlaceholderNUFFT2D(image_shape_2d, trajectory_actual, device)\n",
    "    mc_nufft_for_adjoint = PlaceholderMultiCoilNUFFTOperator(nufft_adj_single_coil)\n",
    "    print(\"INFO: Using PlaceholderNUFFT for initial adjoint image.\")\n",
    "\n",
    "initial_images_mc = mc_nufft_for_adjoint.op_adj(true_kspace_data_mc)\n",
    "# Combine coils for initial viewing (RSS)\n",
    "initial_image_rss = torch.sqrt(torch.sum(torch.abs(initial_images_mc)**2, dim=0))\n",
    "show_image(initial_image_rss, title=\"Initial Image (Adjoint NUFFT + RSS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PINN Reconstructor Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUFFT operator for the PINN (uses actual_trajectory for data fidelity)\n",
    "mc_nufft_pinn = mc_nufft_for_adjoint # Can reuse the same operator if params match\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = SimpleCNN(n_channels_in=1, n_channels_out=num_coils, n_spatial_dims=2).to(device)\n",
    "\n",
    "# Physics Loss Terms\n",
    "physics_terms = []\n",
    "if B0OffResonanceLoss is not None:\n",
    "    b0_loss = B0OffResonanceLoss(b0_map=b0_map, scan_parameters_epi=scan_parameters_epi, weight=0.01)\n",
    "    physics_terms.append(b0_loss)\n",
    "    print(f\"Added {b0_loss.name} to physics terms.\")\n",
    "\n",
    "if GIRFErrorLoss is not None: # Example: also include GIRF placeholder\n",
    "    girf_loss = GIRFErrorLoss(weight=0.001)\n",
    "    physics_terms.append(girf_loss)\n",
    "    print(f\"Added {girf_loss.name} to physics terms.\")\n",
    "\n",
    "# PINNReconstructor\n",
    "reconstructor = PINNReconstructor(\n",
    "    nufft_op=mc_nufft_pinn,\n",
    "    cnn_model=cnn_model,\n",
    "    config=pinn_config,\n",
    "    physics_terms=physics_terms\n",
    ")\n",
    "print(\"PINNReconstructor instantiated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (copied and modified from PINNReconstructor.reconstruct for loss logging)\n",
    "print(f\"Starting reconstruction for {pinn_config['num_epochs']} epochs...\")\n",
    "optimizer = torch.optim.Adam(reconstructor.cnn_model.parameters(), lr=reconstructor.config.get(\"learning_rate\", 1e-3))\n",
    "loss_history = [] # To store loss components per epoch\n",
    "\n",
    "# Prepare input for CNN (RSS of initial multi-coil image, then batched)\n",
    "if reconstructor.cnn_model.n_channels_in == 1 and initial_images_mc.shape[0] > 1:\n",
    "    cnn_input_image = torch.sqrt(torch.sum(torch.abs(initial_images_mc)**2, dim=0, keepdim=True))\n",
    "elif initial_images_mc.shape[0] == reconstructor.cnn_model.n_channels_in:\n",
    "    cnn_input_image = initial_images_mc\n",
    "else:\n",
    "    print(f\"Warning: Channel mismatch for CNN input. Using RSS.\")\n",
    "    cnn_input_image = torch.sqrt(torch.sum(torch.abs(initial_images_mc)**2, dim=0, keepdim=True))\n",
    "cnn_input_image_batched = cnn_input_image.unsqueeze(0).to(reconstructor.device)\n",
    "\n",
    "# Data for loss function (kwargs)\n",
    "loss_fn_kwargs = {\n",
    "    \"trajectory_ideal\": trajectory_ideal.to(reconstructor.device),\n",
    "    \"trajectory_actual\": trajectory_actual.to(reconstructor.device),\n",
    "    \"scan_parameters\": scan_parameters_general, # For Bloch (if used)\n",
    "    \"b0_map\": b0_map.to(reconstructor.device),\n",
    "    \"scan_parameters_epi\": scan_parameters_epi # For B0OffResonanceLoss\n",
    "}\n",
    "\n",
    "reconstructor.cnn_model.train()\n",
    "for epoch in range(pinn_config['num_epochs']):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predicted_output_batched = reconstructor.cnn_model(cnn_input_image_batched)\n",
    "    current_cnn_output = predicted_output_batched[0] # Remove batch dim\n",
    "    \n",
    "    total_loss, loss_comp = reconstructor.loss_function(\n",
    "        current_cnn_output=current_cnn_output,\n",
    "        true_kspace_data_mc=true_kspace_data_mc.to(reconstructor.device),\n",
    "        **loss_fn_kwargs\n",
    "    )\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log losses\n",
    "    epoch_losses = {name: val.item() for name, val in loss_comp.items()}\n",
    "    loss_history.append(epoch_losses)\n",
    "    if epoch % max(1, pinn_config['num_epochs'] // 10) == 0 or epoch == pinn_config['num_epochs'] - 1:\n",
    "        loss_str = \", \".join([f\"{k}: {v:.4e}\" for k,v in epoch_losses.items()])\n",
    "        print(f\"Epoch {epoch}/{pinn_config['num_epochs']}, Losses: [{loss_str}]\")\n",
    "\n",
    "reconstructor.cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    final_prediction_batched = reconstructor.cnn_model(cnn_input_image_batched)\n",
    "reconstructed_image_mc = final_prediction_batched[0]\n",
    "\n",
    "print(\"Reconstruction finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss History\n",
    "if loss_history:\n",
    "    loss_names = loss_history[0].keys()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for loss_name in loss_names:\n",
    "        if loss_name == 'total' or physics_terms: # Plot total and individual physics if physics_terms were added\n",
    "            plt.plot([epoch_loss[loss_name] for epoch_loss in loss_history], label=loss_name)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No loss history to plot.\")\n",
    "\n",
    "# Display final reconstructed image (RSS)\n",
    "reconstructed_image_rss = torch.sqrt(torch.sum(torch.abs(reconstructed_image_mc)**2, dim=0))\n",
    "show_image(reconstructed_image_rss, title=\"PINN Reconstructed Image (RSS)\")\n",
    "\n",
    "# Comparison with Ground Truth and Initial Adjoint\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(torch.abs(gt_image).cpu().numpy(), cmap='gray')\n",
    "axes[0].set_title(\"Ground Truth (Corrected)\"); axes[0].axis('off');\n",
    "\n",
    "axes[1].imshow(torch.abs(initial_image_rss).cpu().numpy(), cmap='gray')\n",
    "axes[1].set_title(\"Initial Adjoint NUFFT (RSS)\"); axes[1].axis('off');\n",
    "\n",
    "axes[2].imshow(torch.abs(reconstructed_image_rss).cpu().numpy(), cmap='gray')\n",
    "axes[2].set_title(\"PINN Reconstructed (RSS)\"); axes[2].axis('off');\n",
    "\n",
    "plt.suptitle(\"B0 Off-Resonance Correction Demo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook demonstrated the setup for a PINN-based B0 off-resonance correction.\n",
    "- We simulated a ground truth image, coil sensitivities, and a B0 map.\n",
    "- K-space data was generated from an off-resonant version of the ground truth.\n",
    "- A `PINNReconstructor` was configured with a CNN, a data fidelity term, and placeholder physics loss terms (including `B0OffResonanceLoss`).\n",
    "- The reconstruction loop was run, and the resulting image can be compared to the ground truth and the initial distorted image.\n",
    "\n",
    "**Next Steps:**\n",
    "- Implement realistic physics models within the `B0OffResonanceLoss` and other physics terms.\n",
    "- Use more realistic k-space trajectories and coil sensitivity maps.\n",
    "- Experiment with different CNN architectures and hyperparameters.\n",
    "- Evaluate the reconstruction quality using appropriate metrics.\n",
    "- If `FAST_DEMO_MODE = False` is used, ensure `reconlib` NUFFT implementations are performant enough or use a more powerful environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
