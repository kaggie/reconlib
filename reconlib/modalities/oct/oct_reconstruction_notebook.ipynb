{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Optical Coherence Tomography (OCT) Reconstruction Example\n",
                "This notebook demonstrates basic OCT image reconstruction, including data simulation using a Fourier-based forward model and Total Variation (TV) regularized reconstruction."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Ensure reconlib is in the Python path\n",
                "if 'reconlib' not in os.getcwd():\n",
                "    # Assuming notebook is in reconlib/modalities/oct/\n",
                "    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '../../..')))\n",
                "else:\n",
                "    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
                "\n",
                "from reconlib.modalities.oct.operators import OCTForwardOperator\n",
                "from reconlib.modalities.oct.reconstructors import tv_reconstruction_oct\n",
                "# Note: tv_reconstruction_oct uses UltrasoundTVCustomRegularizer internally\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define OCT Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Image Parameters (B-scan like: A-scans vs Depth)\n",
                "num_ascan_lines = 128  # Number of lateral A-scans in the B-scan\n",
                "depth_pixels = 256    # Number of pixels along depth for each A-scan\n",
                "image_shape_oct = (num_ascan_lines, depth_pixels)\n",
                "\n",
                "# Physical Parameters for OCT\n",
                "lambda_w_m = 850e-9      # Center wavelength (e.g., 850 nm)\n",
                "z_max_m = 0.002          # Maximum imaging depth (e.g., 2 mm)\n",
                "n_refractive_index = 1.35 # Refractive index of tissue (approximate)\n",
                "\n",
                "# Reconstruction Parameters\n",
                "lambda_tv_oct = 0.01      # TV regularization strength\n",
                "oct_pg_iterations = 30    # Iterations for Proximal Gradient\n",
                "oct_pg_step_size = 0.05   # Step size for Proximal Gradient\n",
                "oct_tv_prox_iters = 5    # Inner iterations for the custom TV prox\n",
                "oct_tv_prox_step = 0.01 # Inner step size for custom TV prox"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create OCT Phantom (Reflectivity Profile)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_oct_phantom(shape, device='cpu'):\n",
                "    # shape: (num_ascan_lines, depth_pixels)\n",
                "    phantom = torch.zeros(shape, dtype=torch.complex64, device=device)\n",
                "    n_ascans, n_depth = shape\n",
                "    \n",
                "    # Simulate a few reflecting layers\n",
                "    layer_depths_pixels = [n_depth // 4, n_depth // 2, n_depth // 4 * 3]\n",
                "    layer_reflectivities = [1.0, 0.7, 0.9]\n",
                "    layer_thickness_pixels = 3\n",
                "    \n",
                "    for i in range(n_ascans):\n",
                "        # Vary layer depths slightly across A-scans for texture\n",
                "        depth_offset = int(5 * np.sin(2 * np.pi * i / n_ascans * 2)) if i % 10 == 0 else 0\n",
                "        for l_idx, depth_px in enumerate(layer_depths_pixels):\n",
                "            start_px = max(0, depth_px + depth_offset - layer_thickness_pixels // 2)\n",
                "            end_px = min(n_depth, depth_px + depth_offset + layer_thickness_pixels // 2 + 1)\n",
                "            if i > n_ascans * 0.2 and i < n_ascans * 0.8: # Make layers discontinuous laterally\n",
                "                 phantom[i, start_px:end_px] = layer_reflectivities[l_idx]\n",
                "            if l_idx == 1 and i > n_ascans * 0.4 and i < n_ascans * 0.6:\n",
                "                 phantom[i, start_px:end_px] = 0 # Create a small gap in 2nd layer\n",
                "\n",
                "    # Add some sparse scatterers\n",
                "    phantom[n_ascans // 3, n_depth // 3 + 10] = 1.2 + 0.3j\n",
                "    phantom[n_ascans // 2, n_depth // 2 + 20] = 0.5 - 0.8j\n",
                "    return phantom\n",
                "\n",
                "oct_phantom = generate_oct_phantom(image_shape_oct, device=device)\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.imshow(torch.abs(oct_phantom).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "plt.title('Original OCT Phantom (Reflectivity Magnitude)')\n",
                "plt.xlabel('Depth Pixels')\n",
                "plt.ylabel('A-scan Line')\n",
                "plt.colorbar(label='Reflectivity')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize OCT Forward Operator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oct_operator_inst = OCTForwardOperator(\n",
                "    image_shape=image_shape_oct,\n",
                "    lambda_w=lambda_w_m,\n",
                "    z_max_m=z_max_m,\n",
                "    n_refractive_index=n_refractive_index,\n",
                "    device=device\n",
                ")\n",
                "print(\"OCTForwardOperator initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Simulate OCT Spectral Data (Forward Projection)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Simulating OCT spectral data (k-space)...\")\n",
                "oct_k_space_clean = oct_operator_inst.op(oct_phantom)\n",
                "print(f\"Simulated clean k-space data shape: {oct_k_space_clean.shape}\")\n",
                "\n",
                "# Add complex Gaussian noise\n",
                "signal_power_oct = torch.mean(torch.abs(oct_k_space_clean)**2)\n",
                "noise_power_ratio_oct = 0.1 # 10% noise relative to signal power\n",
                "noise_std_oct = torch.sqrt(signal_power_oct * noise_power_ratio_oct / 2) # Factor of 2 for complex noise\n",
                "noise_oct = noise_std_oct * (torch.randn_like(oct_k_space_clean.real) + 1j * torch.randn_like(oct_k_space_clean.imag))\n",
                "oct_k_space_noisy = oct_k_space_clean + noise_oct\n",
                "print(f\"Added complex Gaussian noise. Noise STD: {noise_std_oct.item()}\")\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1,2,1)\n",
                "plt.imshow(torch.abs(oct_k_space_clean).cpu().numpy(), aspect='auto', cmap='viridis')\n",
                "plt.title('Clean OCT k-space Data (Magnitude)')\n",
                "plt.xlabel('k-space Samples (Depth Freq.)')\n",
                "plt.ylabel('A-scan Line')\n",
                "plt.colorbar()\n",
                "plt.subplot(1,2,2)\n",
                "plt.imshow(torch.abs(oct_k_space_noisy).cpu().numpy(), aspect='auto', cmap='viridis')\n",
                "plt.title('Noisy OCT k-space Data (Magnitude)')\n",
                "plt.xlabel('k-space Samples (Depth Freq.)')\n",
                "plt.ylabel('A-scan Line')\n",
                "plt.colorbar()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Image Reconstruction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Adjoint Reconstruction (IFFT of k-space data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Performing Adjoint (IFFT-based) reconstruction...\")\n",
                "oct_adjoint_recon = oct_operator_inst.op_adj(oct_k_space_noisy)\n",
                "print(f\"Adjoint reconstructed image shape: {oct_adjoint_recon.shape}\")\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.imshow(torch.abs(oct_adjoint_recon).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "plt.title('Adjoint (IFFT) OCT Reconstruction')\n",
                "plt.xlabel('Depth Pixels')\n",
                "plt.ylabel('A-scan Line')\n",
                "plt.colorbar(label='Reflectivity')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 TV Regularized Reconstruction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Performing TV Regularized OCT Reconstruction (lambda_TV={lambda_tv_oct})...This may take some time.\")\n",
                "\n",
                "oct_tv_recon_image = tv_reconstruction_oct(\n",
                "    y_oct_data=oct_k_space_noisy,\n",
                "    oct_operator=oct_operator_inst,\n",
                "    lambda_tv=lambda_tv_oct,\n",
                "    iterations=oct_pg_iterations,\n",
                "    step_size=oct_pg_step_size,\n",
                "    tv_prox_iterations=oct_tv_prox_iters,\n",
                "    tv_prox_step_size=oct_tv_prox_step,\n",
                "    verbose=True\n",
                ")\n",
                "print(f\"TV Reconstructed OCT image shape: {oct_tv_recon_image.shape}\")\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.imshow(torch.abs(oct_tv_recon_image).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "plt.title(f'TV Regularized OCT Recon (lambda={lambda_tv_oct}, {oct_pg_iterations} iters)')\n",
                "plt.xlabel('Depth Pixels')\n",
                "plt.ylabel('A-scan Line')\n",
                "plt.colorbar(label='Reflectivity')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Comparison of Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "fig.suptitle('OCT Reconstruction Comparison', fontsize=16)\n",
                "\n",
                "im0 = axes[0].imshow(torch.abs(oct_phantom).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "axes[0].set_title('Original Phantom')\n",
                "axes[0].set_xlabel('Depth Pixels'); axes[0].set_ylabel('A-scan Line')\n",
                "fig.colorbar(im0, ax=axes[0], shrink=0.8)\n",
                "\n",
                "im1 = axes[1].imshow(torch.abs(oct_adjoint_recon).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "axes[1].set_title('Adjoint (IFFT) Recon')\n",
                "axes[1].set_xlabel('Depth Pixels'); axes[1].set_ylabel('A-scan Line')\n",
                "fig.colorbar(im1, ax=axes[1], shrink=0.8)\n",
                "\n",
                "im2 = axes[2].imshow(torch.abs(oct_tv_recon_image).cpu().numpy(), cmap='gray', aspect='auto', extent=[0, image_shape_oct[1], image_shape_oct[0], 0])\n",
                "axes[2].set_title(f'TV Recon (lambda={lambda_tv_oct})')\n",
                "axes[2].set_xlabel('Depth Pixels'); axes[2].set_ylabel('A-scan Line')\n",
                "fig.colorbar(im2, ax=axes[2], shrink=0.8)\n",
                "\n",
                "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
                "plt.show()"
            ]
        }
    ]
}
