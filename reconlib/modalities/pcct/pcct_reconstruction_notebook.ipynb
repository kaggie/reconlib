{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon Counting CT (PCCT) Reconstruction Demo\n",
    "This notebook demonstrates simplified reconstruction concepts for PCCT. It covers:\n",
    "1. Basic setup and simulation of multi-energy photon counts using `PCCTProjectorOperator`.\n",
    "2. Reconstruction of a reference attenuation map ($\mu_{ref}$) using `tv_reconstruction_pcct_mu_ref`.\n",
    "3. Iterative reconstruction for a single energy bin's effective attenuation map using `iterative_reconstruction_pcct_bin`.\n",
    "4. An overview of advanced detector effects simulation with `PCCTProjectorOperator`.\n",
    "5. Projection-domain material decomposition for a dual-energy scenario.\n",
    "6. Statistical Image Reconstruction (SIR) for $\mu_{ref}$ using Poisson likelihood.\n",
    "\n",
    "**Key Simplifications in this Placeholder Library:**\n",
    "1.  **Operators:**\n",
    "    *   Uses a very basic Radon transform (projection) and back-projection. A robust, high-quality Radon transform is crucial for CT.\n",
    "    *   Energy dependence in `PCCTProjectorOperator` can be modeled via `energy_scaling_factors`. For K-edge imaging, this requires careful setup of these factors and energy bins.\n",
    "    *   Advanced effects (spectral broadening, pile-up, charge sharing, K-escape) are available but rely on simplified models.\n",
    "2.  **Reconstructors:**\n",
    "    *   `tv_reconstruction_pcct_mu_ref`: Treats the problem as a regularized inversion for $\mu_{ref}$. The underlying `ProximalGradientReconstructor` can now use L2 or Poisson likelihood for data fidelity.\n",
    "    *   `iterative_reconstruction_pcct_bin`: Works on linearized data (`-log(I/I0)`) for a single bin.\n",
    "    *   `IterativeMaterialDecompositionReconstructor`: Reconstructs material basis images from measured data using the `MaterialDecompositionForwardOperator`.\n",
    "3.  **Material Decomposition:** Both image-domain (via `IterativeMaterialDecompositionReconstructor`) and projection-domain (via `calculate_material_thickness_sinograms` and `reconstruct_thickness_maps_from_sinograms`) methods are demonstrated conceptually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from reconlib.operators import Operator # Base class, may not be directly used here\n",
    "    from reconlib.modalities.pcct.operators import PCCTProjectorOperator\n",
    "    from reconlib.modalities.pcct.reconstructors import tv_reconstruction_pcct_mu_ref, iterative_reconstruction_pcct_bin\n",
    "    from reconlib.modalities.pcct.utils import (\n",
    "        generate_pcct_phantom_material_maps, \n",
    "        combine_material_maps_to_mu_ref, \n",
    "        plot_pcct_results, \n",
    "        get_pcct_energy_scaling_factors,\n",
    "        estimate_scatter_sinogram_kernel_based, # Though not explicitly demoed below\n",
    "        simulate_flat_field_for_spectral_calibration, # Though not explicitly demoed below\n",
    "        simulate_flux_scan_for_pileup_calibration # Though not explicitly demoed below\n",
    "    )\n",
    "    from reconlib.modalities.pcct.material_decomposition import (\n",
    "        MaterialDecompositionForwardOperator, \n",
    "        IterativeMaterialDecompositionReconstructor\n",
    "    )\n",
    "    from reconlib.modalities.pcct.projection_domain_decomposition import (\n",
    "        calculate_material_thickness_sinograms, \n",
    "        reconstruct_thickness_maps_from_sinograms,\n",
    "        LinearRadonOperatorPlaceholder # For projection-domain example\n",
    "    )\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}. Make sure reconlib is installed or PYTHONPATH is set correctly.\")\n",
    "    # Example: %env PYTHONPATH=../..\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Parameters and Phantom (Reference Attenuation Map)\n",
    "This section sets up a common phantom and parameters for basic $\mu_{ref}$ reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape_pcct = (64, 64)\n",
    "num_angles_pcct = 90\n",
    "num_detector_pixels_pcct = int(np.floor(image_shape_pcct[0] * np.sqrt(2))) \n",
    "if num_detector_pixels_pcct % 2 == 0: num_detector_pixels_pcct +=1\n",
    "\n",
    "energy_bins = [(20, 50), (50, 80), (80, 120)]\n",
    "source_photons_I0 = torch.tensor([20000.0, 30000.0, 20000.0], device=device)\n",
    "\n",
    "energy_scaling = get_pcct_energy_scaling_factors(\n",
    "    energy_bins_keV=energy_bins, \n",
    "    material_attenuation_model='water_simplified', \n",
    "    reference_energy_keV=60.0,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Energy scaling factors: {energy_scaling}\")\n",
    "\n",
    "material_mus_at_ref_energy = {'soft_tissue': 0.02, 'bone_contrast': 0.05}\n",
    "material_maps = generate_pcct_phantom_material_maps(\n",
    "    image_shape_pcct, \n",
    "    material_attenuations=material_mus_at_ref_energy, \n",
    "    num_features_per_material=2,\n",
    "    device=device\n",
    ")\n",
    "true_mu_reference_map = combine_material_maps_to_mu_ref(\n",
    "    material_maps, material_mus_at_ref_energy, device=device\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(true_mu_reference_map.cpu().numpy(), cmap='viridis')\n",
    "plt.title('True Reference Attenuation Map ($\mu_{ref}$ at 60keV)')\n",
    "plt.xlabel('X (pixels)'); plt.ylabel('Y (pixels)')\n",
    "plt.colorbar(label='Attenuation (e.g., mm$^{-1}$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize PCCT Operator and Simulate Photon Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcct_operator_base = PCCTProjectorOperator(\n",
    "    image_shape=image_shape_pcct,\n",
    "    num_angles=num_angles_pcct,\n",
    "    num_detector_pixels=num_detector_pixels_pcct,\n",
    "    energy_bins_keV=energy_bins,\n",
    "    source_photons_per_bin=source_photons_I0,\n",
    "    energy_scaling_factors=energy_scaling,\n",
    "    add_poisson_noise=True, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "noisy_photon_counts_stack = pcct_operator_base.op(true_mu_reference_map)\n",
    "print(f\"Simulated photon count data shape: {noisy_photon_counts_stack.shape}\")\n",
    "\n",
    "num_bins_to_show = noisy_photon_counts_stack.shape[0]\n",
    "fig, axes = plt.subplots(1, num_bins_to_show, figsize=(num_bins_to_show*5, 4))\n",
    "if num_bins_to_show == 1: axes = [axes]\n",
    "for i in range(num_bins_to_show):\n",
    "    im = axes[i].imshow(noisy_photon_counts_stack[i].cpu().numpy(), aspect='auto', cmap='viridis')\n",
    "    axes[i].set_title(f'Sinogram - Bin {i} ({energy_bins[i][0]}-{energy_bins[i][1]} keV)')\n",
    "    axes[i].set_xlabel('Detector Pixel'); axes[i].set_ylabel('Angle')\n",
    "    fig.colorbar(im, ax=axes[i], label='Photon Counts')\n",
    "plt.suptitle('Simulated Noisy Photon Counts')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Perform Global TV-Regularized Reconstruction for $\mu_{ref}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_tv_pcct_global = 1e-5 \n",
    "iterations_pcct_global = 30 \n",
    "step_size_pcct_global = 1e-6 \n",
    "\n",
    "reconstructed_mu_ref_global = tv_reconstruction_pcct_mu_ref(\n",
    "    y_photon_counts_stack=noisy_photon_counts_stack,\n",
    "    pcct_operator=pcct_operator_base, # Use the operator that generated noisy data\n",
    "    lambda_tv=lambda_tv_pcct_global,\n",
    "    iterations=iterations_pcct_global,\n",
    "    step_size=step_size_pcct_global,\n",
    "    verbose=True,\n",
    "    data_fidelity_mode='l2' # Default L2 norm\n",
    ")\n",
    "print(f\"Global reconstructed mu_ref map shape: {reconstructed_mu_ref_global.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Perform Iterative Reconstruction for a Single Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_bin_idx = 0\n",
    "print(f\"Performing iterative reconstruction for energy bin: {pcct_operator_base.energy_bins_keV[selected_bin_idx]} keV\")\n",
    "\n",
    "noisy_counts_single_bin = noisy_photon_counts_stack[selected_bin_idx, :, :]\n",
    "I0_single_bin = pcct_operator_base.source_photons_per_bin[selected_bin_idx]\n",
    "energy_scale_single_bin = pcct_operator_base.energy_scaling_factors[selected_bin_idx]\n",
    "\n",
    "lambda_tv_iter_bin = 0.001\n",
    "pgd_iters_bin = 30\n",
    "pgd_step_bin = 0.05 \n",
    "\n",
    "reconstructed_mu_effective_bin_iter = iterative_reconstruction_pcct_bin(\n",
    "    noisy_counts_sinogram_bin=noisy_counts_single_bin,\n",
    "    source_photons_bin=I0_single_bin,\n",
    "    image_shape=image_shape_pcct,\n",
    "    num_angles=num_angles_pcct,\n",
    "    num_detector_pixels=num_detector_pixels_pcct,\n",
    "    lambda_tv=lambda_tv_iter_bin,\n",
    "    pgd_iterations=pgd_iters_bin,\n",
    "    pgd_step_size=pgd_step_bin,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "reconstructed_mu_ref_from_iter_bin = reconstructed_mu_effective_bin_iter / (energy_scale_single_bin + 1e-9)\n",
    "print(f\"Iterative reconstruction for bin {selected_bin_idx} complete. Shape: {reconstructed_mu_effective_bin_iter.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Results (Basic $\mu_{ref}$ Reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "max_val = true_mu_reference_map.max().cpu().item() * 1.1\n",
    "min_val = true_mu_reference_map.min().cpu().item()\n",
    "\n",
    "im1 = axes[0].imshow(true_mu_reference_map.cpu().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[0].set_title('True $\mu_{ref}$ Map')\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(reconstructed_mu_ref_global.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[1].set_title(f'Global Recon. $\mu_{ref}$ (TV {iterations_pcct_global} iters)')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "im3 = axes[2].imshow(reconstructed_mu_ref_from_iter_bin.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[2].set_title(f'Iter. Recon. Bin {selected_bin_idx} (scaled to $\mu_{ref}$)')\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "for ax in axes: ax.set_xlabel('X'); ax.set_ylabel('Y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Detector Effects Simulation\n",
    "This section demonstrates how to use `PCCTProjectorOperator` with some of the advanced detector effects enabled, like spectral broadening and pile-up. This is a qualitative demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a basic configuration (can reuse some params from above)\n",
    "adv_effect_config = {\n",
    "    'image_shape': image_shape_pcct,\n",
    "    'num_angles': num_angles_pcct,\n",
    "    'num_detector_pixels': num_detector_pixels_pcct,\n",
    "    'energy_bins_keV': energy_bins,\n",
    "    'source_photons_per_bin': source_photons_I0 * 100, # Increase I0 to make pile-up more evident\n",
    "    'energy_scaling_factors': energy_scaling,\n",
    "    'add_poisson_noise': False, # Turn off noise to see effect clearly\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "# Ideal Detector (no advanced effects)\n",
    "pcct_ideal = PCCTProjectorOperator(**adv_effect_config)\n",
    "ideal_counts = pcct_ideal.op(true_mu_reference_map)\n",
    "\n",
    "# Detector with Spectral Broadening and Pile-up\n",
    "pileup_params_demo = {'method': 'paralyzable', 'dead_time_s': 400e-9, 'acquisition_time_s': 1e-3} # Ensure acq_time matches rate def\n",
    "pcct_with_effects = PCCTProjectorOperator(\n",
    "    **adv_effect_config,\n",
    "    spectral_resolution_keV=20.0, # Example FWHM\n",
    "    pileup_parameters=pileup_params_demo\n",
    ")\n",
    "counts_with_effects = pcct_with_effects.op(true_mu_reference_map)\n",
    "\n",
    "print(f\"Ideal total counts: {torch.sum(ideal_counts).item():.2e}\")\n",
    "print(f\"With effects total counts: {torch.sum(counts_with_effects).item():.2e}\")\n",
    "\n",
    "# Plot a profile from a sinogram bin (e.g., middle angle, first energy bin)\n",
    "angle_idx_profile = num_angles_pcct // 2\n",
    "bin_idx_profile = 0\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ideal_counts[bin_idx_profile, angle_idx_profile, :].cpu().numpy(), label='Ideal Detector')\n",
    "plt.plot(counts_with_effects[bin_idx_profile, angle_idx_profile, :].cpu().numpy(), label='With Spectral Broadening & Pile-up', linestyle='--')\n",
    "plt.title(f'Sinogram Profile (Bin {bin_idx_profile}, Angle {angle_idx_profile})')\n",
    "plt.xlabel('Detector Pixel')\n",
    "plt.ylabel('Photon Counts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Projection-Domain Material Decomposition (Dual-Energy Example)\n",
    "This method involves solving a system of linear equations for each projection ray, assuming that the log-transformed attenuation is a linear combination of material thicknesses and their known MACs. The resulting material-specific thickness sinograms are then reconstructed.\n",
    "\n",
    "**Steps:**\n",
    "1. Define material MACs for two energy bins.\n",
    "2. Create true material basis images (e.g., thickness maps for two materials).\n",
    "3. Synthesize log-transformed sinograms: `L_bin = mac_A_bin * t_A_sino + mac_B_bin * t_B_sino`.\n",
    "4. Use `calculate_material_thickness_sinograms` to solve for `t_A_sino` and `t_B_sino`.\n",
    "5. Use `reconstruct_thickness_maps_from_sinograms` to reconstruct `t_A_map` and `t_B_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s_proj_decomp = (32, 32)\n",
    "n_angles_proj_decomp = 50 # Slightly more angles for better reconstruction\n",
    "n_dets_proj_decomp = int(np.floor(img_s_proj_decomp[0] * np.sqrt(2)) + 1)\n",
    "if n_dets_proj_decomp % 2 == 0: n_dets_proj_decomp +=1\n",
    "\n",
    "# Create true material basis maps (thickness maps)\n",
    "true_material_A_map = torch.zeros(img_s_proj_decomp, device=device, dtype=torch.float32)\n",
    "true_material_A_map[img_s_proj_decomp[0]//4 : img_s_proj_decomp[0]*3//4, \n",
    "                      img_s_proj_decomp[1]//4 : img_s_proj_decomp[1]*3//4] = 1.5 # e.g., thickness in cm\n",
    "\n",
    "true_material_B_map = torch.zeros(img_s_proj_decomp, device=device, dtype=torch.float32)\n",
    "center_y_b, center_x_b = img_s_proj_decomp[0]//2, img_s_proj_decomp[1]//2\n",
    "radius_b = img_s_proj_decomp[0]//5\n",
    "yy_b, xx_b = torch.meshgrid(torch.arange(img_s_proj_decomp[0], device=device), \n",
    "                          torch.arange(img_s_proj_decomp[1], device=device), indexing='ij')\n",
    "mask_circle_b = (xx_b - center_x_b)**2 + (yy_b - center_y_b)**2 < radius_b**2\n",
    "true_material_B_map[mask_circle_b] = 2.0 # e.g., thickness in cm\n",
    "\n",
    "# Define MACs (Mass Attenuation Coefficients) for two materials at two energy bins\n",
    "# These values should be chosen to make the MAC matrix well-conditioned.\n",
    "mac_A_bin1, mac_A_bin2 = 0.25, 0.15 # Material A at Energy Bin 1 and Bin 2\n",
    "mac_B_bin1, mac_B_bin2 = 0.18, 0.22 # Material B at Energy Bin 1 and Bin 2\n",
    "mac_matrix_proj_decomp = torch.tensor([[mac_A_bin1, mac_B_bin1], \n",
    "                                       [mac_A_bin2, mac_B_bin2]], device=device, dtype=torch.float32)\n",
    "\n",
    "# Instantiate a Radon operator (using the placeholder for this example)\n",
    "radon_op_notebook = LinearRadonOperatorPlaceholder(img_s_proj_decomp, n_angles_proj_decomp, n_dets_proj_decomp, device)\n",
    "\n",
    "# Synthesize log-transformed sinograms (L = M*T)\n",
    "tA_sino_true = radon_op_notebook.op(true_material_A_map)\n",
    "tB_sino_true = radon_op_notebook.op(true_material_B_map)\n",
    "\n",
    "L1_sino_true = mac_A_bin1 * tA_sino_true + mac_B_bin1 * tB_sino_true\n",
    "L2_sino_true = mac_A_bin2 * tA_sino_true + mac_B_bin2 * tB_sino_true\n",
    "log_sinos_for_decomp = torch.stack([L1_sino_true, L2_sino_true], dim=0)\n",
    "\n",
    "# Add a small amount of noise (optional, to make it more realistic)\n",
    "# log_sinos_for_decomp += torch.randn_like(log_sinos_for_decomp) * 0.01 * log_sinos_for_decomp.abs().mean()\n",
    "\n",
    "print(f\"Shape of true material A map: {true_material_A_map.shape}\")\n",
    "print(f\"Shape of log-transformed sinograms for decomposition: {log_sinos_for_decomp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate material thickness sinograms\n",
    "thickness_sinos = calculate_material_thickness_sinograms(log_sinos_for_decomp, mac_matrix_proj_decomp)\n",
    "assert thickness_sinos.shape == (2, n_angles_proj_decomp, n_dets_proj_decomp), \"Thickness sinogram shape mismatch\"\n",
    "print(f\"Calculated thickness sinograms shape: {thickness_sinos.shape}\")\n",
    "\n",
    "# Visualize true vs. calculated thickness sinograms (optional)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "im = axes[0,0].imshow(tA_sino_true.cpu().numpy(), cmap='viridis', aspect='auto'); plt.colorbar(im, ax=axes[0,0]); axes[0,0].set_title('True tA Sino')\n",
    "im = axes[0,1].imshow(thickness_sinos[0].cpu().numpy(), cmap='viridis', aspect='auto'); plt.colorbar(im, ax=axes[0,1]); axes[0,1].set_title('Calc tA Sino')\n",
    "im = axes[1,0].imshow(tB_sino_true.cpu().numpy(), cmap='viridis', aspect='auto'); plt.colorbar(im, ax=axes[1,0]); axes[1,0].set_title('True tB Sino')\n",
    "im = axes[1,1].imshow(thickness_sinos[1].cpu().numpy(), cmap='viridis', aspect='auto'); plt.colorbar(im, ax=axes[1,1]); axes[1,1].set_title('Calc tB Sino')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct thickness maps\n",
    "recon_thickness_maps = reconstruct_thickness_maps_from_sinograms(\n",
    "    thickness_sinograms=thickness_sinos,\n",
    "    radon_transform_operator=radon_op_notebook,\n",
    "    image_shape=img_s_proj_decomp,\n",
    "    iterations=30, # Iterations for each material's reconstruction\n",
    "    step_size=1e-2,  # Step size for PGD, might need tuning\n",
    "    enforce_non_negativity=True,\n",
    "    verbose=False # Set to True to see PGD logs for each material\n",
    ")\n",
    "print(f\"Reconstructed thickness maps stack shape: {recon_thickness_maps.shape}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "vm_a = torch.max(true_material_A_map).item()\n",
    "vm_b = torch.max(true_material_B_map).item()\n",
    "\n",
    "im = axes[0,0].imshow(true_material_A_map.cpu().numpy(), cmap='viridis', vmin=0, vmax=vm_a)\n",
    "axes[0,0].set_title('True Material A Map'); fig.colorbar(im, ax=axes[0,0])\n",
    "im = axes[0,1].imshow(recon_thickness_maps[0].cpu().detach().numpy(), cmap='viridis', vmin=0, vmax=vm_a)\n",
    "axes[0,1].set_title('Recon Material A Map'); fig.colorbar(im, ax=axes[0,1])\n",
    "\n",
    "im = axes[1,0].imshow(true_material_B_map.cpu().numpy(), cmap='viridis', vmin=0, vmax=vm_b)\n",
    "axes[1,0].set_title('True Material B Map'); fig.colorbar(im, ax=axes[1,0])\n",
    "im = axes[1,1].imshow(recon_thickness_maps[1].cpu().detach().numpy(), cmap='viridis', vmin=0, vmax=vm_b)\n",
    "axes[1,1].set_title('Recon Material B Map'); fig.colorbar(im, ax=axes[1,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Image Reconstruction (SIR) for $\\mu_{ref}$ (Poisson Likelihood)\n",
    "This section demonstrates using the `tv_reconstruction_pcct_mu_ref` with `data_fidelity_mode='poisson_likelihood'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the base PCCT setup from sections 1 & 2 (true_mu_reference_map, pcct_operator_base config)\n",
    "# We need a PCCTProjectorOperator that does NOT add noise for the reconstruction part.\n",
    "pcct_op_for_sir_recon = PCCTProjectorOperator(\n",
    "    image_shape=image_shape_pcct,\n",
    "    num_angles=num_angles_pcct,\n",
    "    num_detector_pixels=num_detector_pixels_pcct,\n",
    "    energy_bins_keV=energy_bins,\n",
    "    source_photons_per_bin=source_photons_I0,\n",
    "    energy_scaling_factors=energy_scaling,\n",
    "    add_poisson_noise=False, # Critical: projector for recon should be deterministic model\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 1. Generate ideal mean counts (using the deterministic operator)\n",
    "mean_counts_for_sir = pcct_op_for_sir_recon.op(true_mu_reference_map)\n",
    "\n",
    "# 2. Simulate noisy data by applying Poisson noise to the mean counts\n",
    "noisy_counts_for_sir = torch.poisson(torch.clamp(mean_counts_for_sir, min=0.0))\n",
    "print(f\"Shape of noisy data for SIR: {noisy_counts_for_sir.shape}\")\n",
    "\n",
    "# 3. Reconstruct using Poisson likelihood\n",
    "lambda_tv_sir = 1e-5 # May require different tuning than L2\n",
    "iterations_sir = 30\n",
    "step_size_sir = 5e-7 # Step size for Poisson can be much smaller\n",
    "\n",
    "reconstructed_mu_ref_sir = tv_reconstruction_pcct_mu_ref(\n",
    "    y_photon_counts_stack=noisy_counts_for_sir,\n",
    "    pcct_operator=pcct_op_for_sir_recon, # Use the deterministic operator\n",
    "    lambda_tv=lambda_tv_sir,\n",
    "    iterations=iterations_sir,\n",
    "    step_size=step_size_sir,\n",
    "    verbose=True,\n",
    "    data_fidelity_mode='poisson_likelihood'\n",
    ")\n",
    "\n",
    "# 4. (Optional) Reconstruct with L2 for comparison using the same noisy data\n",
    "reconstructed_mu_ref_l2_comp = tv_reconstruction_pcct_mu_ref(\n",
    "    y_photon_counts_stack=noisy_counts_for_sir, # Same noisy data\n",
    "    pcct_operator=pcct_op_for_sir_recon,    # Same deterministic operator\n",
    "    lambda_tv=lambda_tv_pcct_global, # Using previously defined lambda for L2\n",
    "    iterations=iterations_pcct_global,\n",
    "    step_size=step_size_pcct_global,\n",
    "    verbose=True,\n",
    "    data_fidelity_mode='l2'\n",
    ")\n",
    "\n",
    "print(f\"SIR reconstructed mu_ref map shape: {reconstructed_mu_ref_sir.shape}\")\n",
    "print(f\"L2 (for comparison) reconstructed mu_ref map shape: {reconstructed_mu_ref_l2_comp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualize SIR results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "im1 = axes[0].imshow(true_mu_reference_map.cpu().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[0].set_title('True $\mu_{ref}$ Map')\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(reconstructed_mu_ref_l2_comp.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[1].set_title('L2 Recon. from Noisy Data')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "im3 = axes[2].imshow(reconstructed_mu_ref_sir.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val)\n",
    "axes[2].set_title('SIR Recon. (Poisson Likelihood)')\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "for ax in axes: ax.set_xlabel('X'); ax.set_ylabel('Y')\n",
    "plt.suptitle('Comparison of L2 vs. Poisson Likelihood Reconstruction')\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Direction: Iterative Material Decomposition (Image Domain)\n",
    "\n",
    "This section briefly outlines how `IterativeMaterialDecompositionReconstructor` would be used. It builds upon the `MaterialDecompositionForwardOperator`.\n",
    "\n",
    "**Conceptual Steps:**\n",
    "1. Define material properties (`mat_ref_att`, `basis_names`) for N materials.\n",
    "2. Configure a `PCCTProjectorOperator` with appropriate energy bins and other settings (e.g., for K-edge imaging as demonstrated in Python tests, or simpler broad bins).\n",
    "3. Instantiate `MaterialDecompositionForwardOperator` using the above.\n",
    "4. Create `true_basis_images` (e.g., N=3: water, soft tissue, contrast agent maps).\n",
    "5. Simulate `measured_sinograms` using the forward operator: `mat_decomp_op.op(true_basis_images)`.\n",
    "6. Instantiate `IterativeMaterialDecompositionReconstructor` with parameters like iterations, step size, and optionally, per-material regularizers and `enforce_non_negativity=True`.\n",
    "7. Compute an `initial_estimate` (e.g., `mat_decomp_op.op_adj(measured_sinograms)`).\n",
    "8. Perform reconstruction: `reconstructed_basis_images = reconstructor.reconstruct(measured_sinograms, mat_decomp_op, initial_estimate)`.\n",
    "9. Visualize the `true_basis_images` and `reconstructed_basis_images` side-by-side.\n",
    "\n",
    "This demonstrates an end-to-end simulation and iterative, model-based material decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** The placeholder Radon/Back-projection and the simplified energy dependence make this demo highly illustrative. The reconstruction quality will be limited. For actual PCCT, advanced operators (accurate Radon, physics-based spectral modeling) and reconstructors (e.g., statistical iterative methods that handle Poisson noise, material decomposition algorithms) are necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
