{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Synthetic Aperture Radar (SAR) Reconstruction Example\n",
                "This notebook demonstrates basic SAR image reconstruction from simulated k-space (visibility) data using a Fourier-based forward model with physically derived k-space sampling and Total Variation (TV) regularized reconstruction."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Ensure reconlib is in the Python path\n",
                "if 'reconlib' not in os.getcwd():\n",
                "    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '../../..')))\n",
                "else:\n",
                "    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
                "\n",
                "from reconlib.modalities.sar.operators import SARForwardOperator\n",
                "from reconlib.modalities.sar.reconstructors import tv_reconstruction_sar\n",
                "# tv_reconstruction_sar uses UltrasoundTVCustomRegularizer by default\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define SAR Parameters\n",
                "We will define image parameters, physical parameters for the SAR acquisition (which determine k-space sampling), and reconstruction algorithm parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Image Parameters\n",
                "Ny, Nx = 128, 128  # Image height (Ny) and width (Nx)\n",
                "image_shape_sar = (Ny, Nx)\n",
                "\n",
                "# SAR Specific Physical Parameters (for uv-coordinate generation)\n",
                "num_angles = 256 # Number of azimuth angles for k-space sampling\n",
                "sensor_azimuth_angles = torch.linspace(0, 2 * np.pi, num_angles, device=device) # Sample full circle\n",
                "wavelength = 0.03  # Example: 0.03m (X-band, 10 GHz)\n",
                "# FOV in meters (Ny corresponds to fov_y, Nx to fov_x)\n",
                "fov = (20.0, 20.0)  # e.g., 20m x 20m scene\n",
                "\n",
                "print(f\"Defined physical parameters for {num_angles} k-space samples.\")\n",
                "\n",
                "# Reconstruction Parameters\n",
                "lambda_tv_sar = 0.001\n",
                "sar_pg_iterations = 50\n",
                "sar_pg_step_size = 0.05\n",
                "sar_tv_prox_iters = 5\n",
                "sar_tv_prox_step = 0.01"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create SAR Target Reflectivity Phantom"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_sar_phantom(shape, device='cpu'):\n",
                "    # shape: (Ny, Nx)\n",
                "    phantom = torch.zeros(shape, dtype=torch.complex64, device=device)\n",
                "    h, w = shape\n",
                "    \n",
                "    # Simulate a few point-like targets and a rectangular area\n",
                "    phantom[h // 4, w // 4] = 2.0 + 1j\n",
                "    phantom[h // 2, w // 2 + w // 8] = 1.5 - 0.5j\n",
                "    phantom[int(h*0.7), int(w*0.6)] = 2.5\n",
                "    \n",
                "    # Rectangular region\n",
                "    phantom[int(h*0.2):int(h*0.3), int(w*0.6):int(w*0.8)] = 1.0\n",
                "    return phantom\n",
                "\n",
                "sar_phantom = generate_sar_phantom(image_shape_sar, device=device)\n",
                "\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.imshow(torch.abs(sar_phantom).cpu().numpy(), cmap='gray', origin='lower')\n",
                "plt.title('Original SAR Target Phantom (Reflectivity Magnitude)')\n",
                "plt.xlabel('X-pixels (Range/Azimuth)')\n",
                "plt.ylabel('Y-pixels (Range/Azimuth)')\n",
                "plt.colorbar(label='Reflectivity')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize SAR Forward Operator\n",
                "We initialize the `SARForwardOperator` using the defined image and physical parameters. We'll explicitly use the FFT-based mode."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize SARForwardOperator using physical parameters\n",
                "# This will use the FFT-based fallback by default (use_nufft=False)\n",
                "sar_operator_inst = SARForwardOperator(\n",
                "    image_shape=image_shape_sar,\n",
                "    wavelength=wavelength,\n",
                "    sensor_azimuth_angles=sensor_azimuth_angles,\n",
                "    fov=fov,\n",
                "    device=device,\n",
                "    use_nufft=False # Explicitly use FFT-based operator\n",
                ")\n",
                "print(\"SARForwardOperator initialized (using FFT-based mode).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Simulate SAR Raw Data (Visibilities)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Simulating SAR raw data (visibilities)...\")\n",
                "visibilities_clean = sar_operator_inst.op(sar_phantom)\n",
                "print(f\"Simulated clean visibilities shape: {visibilities_clean.shape}\")\n",
                "\n",
                "# Add complex Gaussian noise\n",
                "signal_power_sar = torch.mean(torch.abs(visibilities_clean)**2)\n",
                "noise_power_ratio_sar = 0.05 # 5% noise relative to signal power\n",
                "noise_std_sar = torch.sqrt(signal_power_sar * noise_power_ratio_sar / 2) # Factor of 2 for complex\n",
                "noise_sar = noise_std_sar * (torch.randn_like(visibilities_clean.real) + 1j * torch.randn_like(visibilities_clean.imag))\n",
                "visibilities_noisy = visibilities_clean + noise_sar\n",
                "print(f\"Added complex Gaussian noise. Noise STD: {noise_std_sar.item()}\")\n",
                "\n",
                "# Visualize k-space samples (optional, can be dense)\n",
                "plt.figure(figsize=(6,6))\n",
                "uv_cpu = sar_operator_inst.raw_uv_coordinates.cpu().numpy()\n",
                "plt.scatter(uv_cpu[:,0], uv_cpu[:,1], c=torch.abs(visibilities_noisy).cpu().numpy(), cmap='viridis', s=5, vmax=torch.quantile(torch.abs(visibilities_noisy),0.95).cpu())\n",
                "plt.title('Noisy k-space Samples (Visibilities Magnitude)')\n",
                "plt.xlabel('u (FFT-scaled kx-related)')\n",
                "plt.ylabel('v (FFT-scaled ky-related)')\n",
                "plt.colorbar()\n",
                "plt.axis('square')\n",
                "# plt.xlim(-Nx/2 -5, Nx/2 + 5); plt.ylim(-Ny/2 -5, Ny/2 + 5) # Removed to auto-scale\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Image Reconstruction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Adjoint Reconstruction ('Dirty Image')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Performing Adjoint (Dirty Image) reconstruction...\")\n",
                "sar_dirty_image = sar_operator_inst.op_adj(visibilities_noisy)\n",
                "print(f\"Dirty image shape: {sar_dirty_image.shape}\")\n",
                "\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.imshow(torch.abs(sar_dirty_image).cpu().numpy(), cmap='gray', origin='lower')\n",
                "plt.title('SAR Adjoint Recon (Dirty Image)')\n",
                "plt.xlabel('X-pixels'); plt.ylabel('Y-pixels')\n",
                "plt.colorbar(label='Magnitude')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 TV Regularized Reconstruction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Performing TV Regularized SAR Reconstruction (lambda_TV={lambda_tv_sar})...This may take some time.\")\n",
                "\n",
                "sar_tv_recon_image = tv_reconstruction_sar(\n",
                "    y_sar_data=visibilities_noisy,\n",
                "    sar_operator=sar_operator_inst,\n",
                "    lambda_tv=lambda_tv_sar,\n",
                "    iterations=sar_pg_iterations,\n",
                "    step_size=sar_pg_step_size,\n",
                "    tv_prox_iterations=sar_tv_prox_iters,\n",
                "    tv_prox_step_size=sar_tv_prox_step,\n",
                "    verbose=True\n",
                ")\n",
                "print(f\"TV Reconstructed SAR image shape: {sar_tv_recon_image.shape}\")\n",
                "\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.imshow(torch.abs(sar_tv_recon_image).cpu().numpy(), cmap='gray', origin='lower')\n",
                "plt.title(f'TV Regularized SAR Recon (lambda={lambda_tv_sar}, {sar_pg_iterations} iters)')\n",
                "plt.xlabel('X-pixels'); plt.ylabel('Y-pixels')\n",
                "plt.colorbar(label='Magnitude')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Comparison of Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "fig.suptitle('SAR Reconstruction Comparison', fontsize=16)\n",
                "\n",
                "im0 = axes[0].imshow(torch.abs(sar_phantom).cpu().numpy(), cmap='gray', origin='lower')\n",
                "axes[0].set_title('Original SAR Phantom')\n",
                "axes[0].set_xlabel('X-pixels'); axes[0].set_ylabel('Y-pixels')\n",
                "fig.colorbar(im0, ax=axes[0], shrink=0.8)\n",
                "\n",
                "im1 = axes[1].imshow(torch.abs(sar_dirty_image).cpu().numpy(), cmap='gray', origin='lower')\n",
                "axes[1].set_title('Adjoint (Dirty Image) Recon')\n",
                "axes[1].set_xlabel('X-pixels'); axes[1].set_ylabel('Y-pixels')\n",
                "fig.colorbar(im1, ax=axes[1], shrink=0.8)\n",
                "\n",
                "im2 = axes[2].imshow(torch.abs(sar_tv_recon_image).cpu().numpy(), cmap='gray', origin='lower')\n",
                "axes[2].set_title(f'TV Regularized SAR Recon (lambda={lambda_tv_sar})')\n",
                "axes[2].set_xlabel('X-pixels'); axes[2].set_ylabel('Y-pixels')\n",
                "fig.colorbar(im2, ax=axes[2], shrink=0.8)\n",
                "\n",
                "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
                "plt.show()"
            ]
        }
    ]
}
