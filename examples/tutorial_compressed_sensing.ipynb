{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Guide: Compressed Sensing MRI Reconstruction with L1-Wavelet Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates Compressed Sensing (CS) for MRI reconstruction using `reconlib`. We will specifically focus on L1 regularization in the Wavelet domain to reconstruct an image from undersampled k-space data.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Undersampling:** Acquiring fewer k-space samples than required by the Nyquist criterion, enabling faster scans.\n",
    "- **Sparsity:** Many images, or their representations in a specific domain (like wavelets), have few non-zero coefficients. CS leverages this.\n",
    "- **L1 Regularization:** Promotes sparsity by penalizing the L1 norm of the coefficients in the sparsifying domain.\n",
    "- **Iterative Reconstruction:** Solvers like FISTA are used to solve the resulting optimization problem.\n",
    "\n",
    "**Notebook Outline:**\n",
    "1. Setup and Imports.\n",
    "2. Define simulation parameters (image size, undersampling, noise, wavelet, CS strength).\n",
    "3. Generate phantom and fully sampled k-space trajectory.\n",
    "4. Simulate full k-space data, then retrospectively undersample it and add noise.\n",
    "5. Set up NUFFT operator for reconstruction from undersampled data.\n",
    "6. Reconstruct using Zero-Filled Adjoint (for baseline comparison).\n",
    "7. Reconstruct using Conjugate Gradient (for non-CS iterative comparison).\n",
    "8. Perform Compressed Sensing reconstruction using FISTA and L1-Wavelet regularization.\n",
    "9. Visualize and compare all results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ReconLib imports\n",
    "try:\n",
    "    from reconlib.nufft import NUFFT2D\n",
    "    from reconlib.solvers import fista_reconstruction, conjugate_gradient_reconstruction\n",
    "    from reconlib.wavelets_scratch import WaveletRegularizationTerm \n",
    "    # For data simulation\n",
    "    from iternufft import generate_phantom_2d, generate_radial_trajectory_2d\n",
    "    print(\"Successfully imported reconlib components.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Please ensure reconlib is installed and iternufft.py is in the Python path.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "FULL_N_SPOKES = 128  # Number of spokes for a fully sampled trajectory\n",
    "N_SAMPLES_PER_SPOKE = int(IMAGE_SIZE * 1.5) # Samples along each spoke\n",
    "\n",
    "# Undersampling parameters\n",
    "UNDERSAMPLING_FACTOR = 4 # e.g., 4x acceleration\n",
    "N_SPOKES_UNDERSAMPLED = FULL_N_SPOKES // UNDERSAMPLING_FACTOR\n",
    "\n",
    "NOISE_STD_PERCENT = 0.02 # Noise level (percentage of max clean k-space signal)\n",
    "\n",
    "# Wavelet and CS parameters\n",
    "WAVELET_NAME = 'db4' # Daubechies 4\n",
    "WAVELET_LEVELS = 3\n",
    "LAMBDA_CS = 0.002 # Regularization strength for L1-wavelet CS\n",
    "\n",
    "print(f\"Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Fully Sampled Spokes: {FULL_N_SPOKES}\")\n",
    "print(f\"Undersampled Spokes: {N_SPOKES_UNDERSAMPLED} ({UNDERSAMPLING_FACTOR}x acceleration)\")\n",
    "print(f\"Noise Level: {NOISE_STD_PERCENT*100}%\" )\n",
    "print(f\"Wavelet: {WAVELET_NAME}, Levels: {WAVELET_LEVELS}\")\n",
    "print(f\"CS Lambda: {LAMBDA_CS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Phantom and Full K-Space Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom_img = generate_phantom_2d(size=IMAGE_SIZE, device=device)\n",
    "phantom_complex = phantom_img.to(torch.complex64)\n",
    "\n",
    "k_trajectory_full = generate_radial_trajectory_2d(\n",
    "    num_spokes=FULL_N_SPOKES,\n",
    "    samples_per_spoke=N_SAMPLES_PER_SPOKE,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(phantom_complex.abs().cpu().numpy(), cmap='gray')\n",
    "axes[0].set_title(f\"Original Phantom ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
    "axes[0].axis('off')\n",
    "axes[1].scatter(k_trajectory_full[:, 0].cpu().numpy(), k_trajectory_full[:, 1].cpu().numpy(), s=0.1)\n",
    "axes[1].set_title(f\"Fully Sampled Trajectory ({FULL_N_SPOKES} spokes)\")\n",
    "axes[1].set_xlabel(\"kx\"); axes[1].set_ylabel(\"ky\")\n",
    "axes[1].axis('square');\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate Full K-space Data, Undersample, and Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup NUFFT for simulation (using full trajectory)\n",
    "nufft_params_sim = {\n",
    "    'image_shape': (IMAGE_SIZE, IMAGE_SIZE), 'k_trajectory': k_trajectory_full,\n",
    "    'oversamp_factor': (2.0, 2.0), 'kb_J': (4, 4),\n",
    "    'kb_alpha': (2.34 * 4, 2.34 * 4), 'Ld': (1024, 1024),\n",
    "    'kb_m': (0.0, 0.0), 'device': device\n",
    "}\n",
    "nufft_op_sim = NUFFT2D(**nufft_params_sim)\n",
    "\n",
    "print(\"Simulating fully sampled k-space data...\")\n",
    "k_space_data_full_clean = nufft_op_sim.forward(phantom_complex)\n",
    "\n",
    "# Undersampling: Randomly select spokes\n",
    "num_total_points_full = k_trajectory_full.shape[0]\n",
    "points_per_spoke = N_SAMPLES_PER_SPOKE\n",
    "\n",
    "spoke_indices = torch.arange(FULL_N_SPOKES)\n",
    "selected_spoke_indices = spoke_indices[torch.randperm(FULL_N_SPOKES)[:N_SPOKES_UNDERSAMPLED]]\n",
    "\n",
    "undersampling_mask = torch.zeros(num_total_points_full, dtype=torch.bool, device=device)\n",
    "for i in selected_spoke_indices:\n",
    "    undersampling_mask[i*points_per_spoke : (i+1)*points_per_spoke] = True\n",
    "\n",
    "k_trajectory_undersampled = k_trajectory_full[undersampling_mask, :]\n",
    "k_space_data_undersampled_clean = k_space_data_full_clean[undersampling_mask]\n",
    "print(f\"Undersampled trajectory shape: {k_trajectory_undersampled.shape}\")\n",
    "print(f\"Undersampled clean k-space shape: {k_space_data_undersampled_clean.shape}\")\n",
    "\n",
    "# Add noise to the undersampled k-space data\n",
    "noise_std_val = NOISE_STD_PERCENT * torch.max(torch.abs(k_space_data_undersampled_clean))\n",
    "complex_noise = torch.complex(\n",
    "    torch.randn_like(k_space_data_undersampled_clean.real) * noise_std_val,\n",
    "    torch.randn_like(k_space_data_undersampled_clean.imag) * noise_std_val\n",
    ").to(device)\n",
    "k_space_data_undersampled_noisy = k_space_data_undersampled_clean + complex_noise\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].scatter(k_trajectory_undersampled[:, 0].cpu().numpy(), k_trajectory_undersampled[:, 1].cpu().numpy(), s=0.1, color='blue')\n",
    "axes[0].set_title(f\"Undersampled Trajectory ({N_SPOKES_UNDERSAMPLED} spokes)\")\n",
    "axes[0].set_xlabel(\"kx\"); axes[0].set_ylabel(\"ky\")\n",
    "axes[0].axis('square');\n",
    "\n",
    "im = axes[1].scatter(k_trajectory_undersampled[:,0].cpu(), k_trajectory_undersampled[:,1].cpu(), \n",
    "                c=torch.log(torch.abs(k_space_data_undersampled_noisy.cpu()) + 1e-9), \n",
    "                s=1, cmap='viridis')\n",
    "axes[1].set_title(\"Undersampled Noisy K-Space\")\n",
    "axes[1].set_xlabel(\"kx\"); axes[1].set_ylabel(\"ky\")\n",
    "axes[1].axis('square');\n",
    "fig.colorbar(im, ax=axes[1], label=\"log|k-space data|\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 5. NUFFT Operator for Reconstruction" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. NUFFT Operator for Reconstruction ---\n",
    "# This NUFFT operator will be configured with the UNDERSAMPLED k-space trajectory.\n",
    "# It will be used by all subsequent reconstruction methods.\n",
    "\n",
    "print(\"\\n--- Setting up NUFFT Operator for Reconstruction (Undersampled Data) ---\")\n",
    "try:\n",
    "    # Ensure k_trajectory_undersampled and other params are available\n",
    "    if 'k_trajectory_undersampled' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'NUFFT2D' not in globals():\n",
    "        raise NameError(\"Required variables for NUFFT setup are not defined. Run previous cells.\")\n",
    "\n",
    "    nufft_recon_kwargs_cs = {\n",
    "        'oversamp_factor': (2.0, 2.0), \n",
    "        'kb_J': (4, 4),      \n",
    "        'kb_alpha': (2.34 * 4, 2.34 * 4), \n",
    "        'Ld': (1024, 1024), \n",
    "        'kb_m': (0.0, 0.0)\n",
    "        # 'density_comp_weights': None is implied. For CS, the regularization handles artifacts.\n",
    "        # If we wanted to use some basic DCF, it could be passed here.\n",
    "    }\n",
    "    \n",
    "    # This nufft_op_recon will be used for all reconstruction methods below\n",
    "    nufft_op_recon = NUFFT2D(\n",
    "        image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        k_trajectory=k_trajectory_undersampled, # CRITICAL: Use undersampled trajectory\n",
    "        device=device,\n",
    "        **nufft_recon_kwargs_cs \n",
    "    )\n",
    "    print(f\"NUFFT2D operator for reconstruction created successfully.\")\n",
    "    print(f\"Configured with undersampled trajectory shape: {k_trajectory_undersampled.shape}\")\n",
    "    if hasattr(nufft_op_recon, 'density_comp_weights') and nufft_op_recon.density_comp_weights is not None:\n",
    "         print(f\"NUFFT op has density_comp_weights of shape: {nufft_op_recon.density_comp_weights.shape}\")\n",
    "    else:\n",
    "        print(\"NUFFT op configured without explicit external density_comp_weights (will use internal default if any).\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Could not set up NUFFT operator.\")\n",
    "    nufft_op_recon = None # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred setting up the NUFFT operator: {e}\")\n",
    "    nufft_op_recon = None # Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 6. Comparison: Zero-Filled Adjoint Reconstruction" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Comparison: Zero-Filled Adjoint Reconstruction ---\n",
    "# This is the simplest possible reconstruction from the undersampled k-space data.\n",
    "# It involves applying the adjoint NUFFT operation directly.\n",
    "# The nufft_op_recon (configured with undersampled trajectory and default DCF) is used.\n",
    "\n",
    "print(\"\\n--- Performing Zero-Filled Adjoint Reconstruction ---\")\n",
    "try:\n",
    "    if 'nufft_op_recon' not in globals() or \\\n",
    "       'k_space_data_undersampled_noisy' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals():\n",
    "        raise NameError(\"Required variables (nufft_op_recon, k_space_data_undersampled_noisy, IMAGE_SIZE) not found.\")\n",
    "\n",
    "    if nufft_op_recon is None:\n",
    "        raise ValueError(\"nufft_op_recon was not properly initialized in a previous cell.\")\n",
    "\n",
    "    recon_adj = nufft_op_recon.adjoint(k_space_data_undersampled_noisy)\n",
    "    \n",
    "    print(f\"Zero-filled adjoint reconstruction complete. Shape: {recon_adj.shape}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_adj.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(\"Recon: Zero-Filled Adjoint (Undersampled)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Cannot perform adjoint reconstruction.\")\n",
    "    recon_adj = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during adjoint reconstruction: {e}\")\n",
    "    recon_adj = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 7. Comparison: Conjugate Gradient Reconstruction" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Comparison: Conjugate Gradient Reconstruction ---\n",
    "# This reconstruction uses the Conjugate Gradient algorithm on the undersampled\n",
    "# k-space data, without any explicit sparsity regularization.\n",
    "# It solves the normal equations A^H A x = A^H y, where A is the NUFFT operator\n",
    "# (nufft_op_recon) configured with the undersampled trajectory and default/minimal DCF.\n",
    "\n",
    "print(\"\\n--- Performing Conjugate Gradient Reconstruction (Undersampled Data) ---\")\n",
    "\n",
    "# CG parameters\n",
    "CG_ITERS_COMPARISON = 20 # Number of CG iterations\n",
    "CG_TOL_COMPARISON = 1e-6   # Tolerance for CG convergence\n",
    "\n",
    "try:\n",
    "    # Ensure necessary variables/classes are defined\n",
    "    if 'k_space_data_undersampled_noisy' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'k_trajectory_undersampled' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'nufft_recon_kwargs_cs' not in globals() or \\\n",
    "       'NUFFT2D' not in globals() or \\\n",
    "       'conjugate_gradient_reconstruction' not in globals(): # Defined in cell 3 (imports)\n",
    "        raise NameError(\"One or more required variables/functions for CG recon are not defined. Run previous cells.\")\n",
    "\n",
    "    print(f\"Starting CG reconstruction (iters={CG_ITERS_COMPARISON}, tol={CG_TOL_COMPARISON:.1e})...\")\n",
    "    \n",
    "    # nufft_op_recon (from cell 11) is already configured with the undersampled trajectory.\n",
    "    # The nufft_recon_kwargs_cs (from cell 11) will be used by the solver.\n",
    "    recon_cg_undersampled = conjugate_gradient_reconstruction(\n",
    "        kspace_data=k_space_data_undersampled_noisy,\n",
    "        sampling_points=k_trajectory_undersampled,\n",
    "        image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        nufft_operator_class=NUFFT2D,\n",
    "        nufft_kwargs=nufft_recon_kwargs_cs, # Using the same NUFFT params as CS recon for consistency\n",
    "        max_iters=CG_ITERS_COMPARISON,\n",
    "        tol=CG_TOL_COMPARISON\n",
    "        # use_voronoi=False, voronoi_weights=None by default\n",
    "    )\n",
    "    \n",
    "    print(\"CG reconstruction (undersampled data) complete.\")\n",
    "    print(f\"CG reconstructed image shape: {recon_cg_undersampled.shape}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_cg_undersampled.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(f\"Recon: CG (Undersampled, {CG_ITERS_COMPARISON} iters)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Could not perform CG reconstruction.\")\n",
    "    recon_cg_undersampled = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during CG reconstruction: {e}\")\n",
    "    recon_cg_undersampled = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 8. Compressed Sensing Reconstruction (L1-Wavelet)" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Compressed Sensing Reconstruction (L1-Wavelet) ---\n",
    "# Here, we use the FISTA algorithm with the WaveletRegularizationTerm.\n",
    "# This regularizer applies an L1 penalty to the wavelet coefficients of the image,\n",
    "# promoting sparsity in the wavelet domain.\n",
    "\n",
    "print(\"\\n--- Performing Compressed Sensing (L1-Wavelet) Reconstruction ---\")\n",
    "\n",
    "# FISTA parameters for CS\n",
    "FISTA_ITERS_CS = 75  # May need more iterations for CS\n",
    "FISTA_TOL_CS = 1e-5\n",
    "# LAMBDA_CS, WAVELET_NAME, WAVELET_LEVELS are defined in cell with index 5 (\"Simulation Parameters\")\n",
    "\n",
    "try:\n",
    "    # Ensure necessary variables/classes are defined\n",
    "    if 'k_space_data_undersampled_noisy' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'k_trajectory_undersampled' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'nufft_op_recon' not in globals() or \\\n",
    "       'fista_reconstruction' not in globals() or \\\n",
    "       'WaveletRegularizationTerm' not in globals() or \\\n",
    "       'LAMBDA_CS' not in globals() or \\\n",
    "       'WAVELET_NAME' not in globals() or \\\n",
    "       'WAVELET_LEVELS' not in globals():\n",
    "        raise NameError(\"One or more required variables/classes for CS recon are not defined. Run previous cells.\")\n",
    "\n",
    "    # 1. Instantiate WaveletRegularizationTerm\n",
    "    cs_regularizer = WaveletRegularizationTerm(\n",
    "        lambda_reg=LAMBDA_CS,       # This lambda is used by the prox op for thresholding\n",
    "        wavelet_name=WAVELET_NAME,\n",
    "        level=WAVELET_LEVELS,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"WaveletRegularizationTerm instantiated: wavelet='{WAVELET_NAME}', levels={WAVELET_LEVELS}, lambda_cs={LAMBDA_CS}\")\n",
    "\n",
    "    # 2. Perform FISTA reconstruction\n",
    "    # The nufft_op_recon is already configured with the undersampled trajectory\n",
    "    # and appropriate NUFFT parameters (but no explicit DCF, as CS handles it).\n",
    "    print(f\"Starting FISTA for CS (iters={FISTA_ITERS_CS}, tol={FISTA_TOL_CS:.1e})...\")\n",
    "    \n",
    "    recon_cs = fista_reconstruction(\n",
    "        kspace_data=k_space_data_undersampled_noisy,\n",
    "        sampling_points=k_trajectory_undersampled, # Passed to NUFFT op\n",
    "        image_shape=(IMAGE_SIZE, IMAGE_SIZE),      # Passed to NUFFT op\n",
    "        nufft_operator_class=NUFFT2D,              # NUFFT op class\n",
    "        nufft_kwargs=nufft_recon_kwargs_cs,        # NUFFT op parameters (from cell 11)\n",
    "        regularizer=cs_regularizer,\n",
    "        lambda_reg=1.0, # Set to 1.0, as WaveletRegularizationTerm's lambda_reg is the true strength. \n",
    "        max_iters=FISTA_ITERS_CS,\n",
    "        tol=FISTA_TOL_CS,\n",
    "        verbose=True # Enable verbose output for FISTA\n",
    "    )\n",
    "    \n",
    "    print(\"Compressed Sensing reconstruction complete.\")\n",
    "    print(f\"CS reconstructed image shape: {recon_cs.shape}\")\n",
    "\n",
    "    # 3. Display the CS reconstructed image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_cs.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(f\"CS Recon: FISTA + L1-Wavelet (lambda={LAMBDA_CS}, {FISTA_ITERS_CS} iters)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Could not perform CS reconstruction.\")\n",
    "    recon_cs = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during CS reconstruction: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    recon_cs = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 9. Results Visualization and Comparison" ]
  },
  { "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [] },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 10. Conclusion and Discussion" ]
  },
  { "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [] }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": { "name": "ipython", "version": 3 },
   "file_extension": ".py", "mimetype": "text/x-python",
   "name": "python", "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3", "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
