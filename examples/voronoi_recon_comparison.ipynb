{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voronoi-Weighted Non-Cartesian MRI Reconstruction Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a hands-on demonstration of non-Cartesian Magnetic Resonance Imaging (MRI) reconstruction. We focus on utilizing Voronoi tessellation for density compensation and compare its performance against other common reconstruction approaches.\n",
    "\n",
    "**Key Concepts Covered:**\n",
    "*   **Non-Cartesian Sampling:** Unlike conventional Cartesian sampling, non-Cartesian trajectories (e.g., radial, spiral) can offer advantages like motion robustness or faster scanning. However, they require specialized reconstruction algorithms.\n",
    "*   **Density Compensation:** When gridding non-Cartesian k-space data onto a Cartesian grid for FFT, regions with higher sample density are overrepresented. Density Compensation Factors (DCF) are used to correct for this, typically by down-weighting densely sampled regions.\n",
    "*   **Voronoi Density Compensation:** This method calculates DCF based on the area (2D) or volume (3D) of Voronoi cells surrounding each k-space sample. Larger cells (sparser sampling) get smaller weights (as weight = 1/area).\n",
    "*   **NUFFT (Non-Uniform Fast Fourier Transform):** An essential tool for efficiently mapping data between a non-Cartesian grid in k-space and a Cartesian grid in image space.\n",
    "*   **Iterative Reconstruction:** Algorithms like Conjugate Gradient (CG) can iteratively solve the reconstruction problem, often leading to better image quality than simple gridding, especially when combined with accurate system modeling (including NUFFT and DCF).\n",
    "\n",
    "**Notebook Workflow:**\n",
    "1.  **Setup and Imports:** Load necessary libraries and modules from `reconlib`.\n",
    "2.  **Data Generation:** Create a 2D Shepp-Logan phantom and simulate non-Cartesian (radial) k-space data using a NUFFT forward operation. Noise is added to simulate realistic conditions.\n",
    "3.  **Voronoi Weight Calculation:** Compute Voronoi density compensation weights from the k-space trajectory.\n",
    "4.  **Image Reconstruction:** Reconstruct the image using three different methods:\n",
    "    *   Conjugate Gradient (CG) with Voronoi weights.\n",
    "    *   Simple gridding (adjoint NUFFT) using the NUFFT operator's default density compensation (if any).\n",
    "    *   Conjugate Gradient (CG) using the NUFFT operator's default density compensation.\n",
    "5.  **Comparison:** Visualize the reconstructed images and compare them qualitatively and quantitatively (MSE, PSNR, SSIM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Attempt to import reconlib\n",
    "try:\n",
    "    import reconlib\n",
    "    from reconlib.nufft import NUFFT2D # Specific class for 2D\n",
    "    from reconlib.solvers import conjugate_gradient_reconstruction\n",
    "    from reconlib.voronoi.density_weights_pytorch import compute_voronoi_density_weights_pytorch # Corrected path\n",
    "    from iternufft import generate_radial_trajectory_2d # Corrected import\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing reconlib or iternufft: {e}\")\n",
    "    print(\"Please ensure reconlib is installed and accessible in your Python path.\")\n",
    "    print(\"You might need to run 'pip install -e .' from the root of the repository.\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "if 'reconlib' in locals() or 'reconlib' in globals():\n",
    "    print(f\"reconlib version: {reconlib.__version__ if hasattr(reconlib, '__version__') else 'unknown'}\")\n",
    "# Also print iternufft version if possible, though it might not have __version__\n",
    "try:\n",
    "    import iternufft\n",
    "    print(f\"iternufft version: {iternufft.__version__ if hasattr(iternufft, '__version__') else 'unknown'}\")\n",
    "except ImportError:\n",
    "    print(\"iternufft not found, which is needed for generate_radial_trajectory_2d.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Phantom and Simulate K-Space Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Data Generation ---\n",
    "IMAGE_SIZE = 128\n",
    "N_SPOKES = IMAGE_SIZE # Number of radial spokes\n",
    "N_SAMPLES_PER_SPOKE = int(IMAGE_SIZE * 1.5) # Oversampling along spokes\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Generate Phantom ---\n",
    "print(\"\\n--- Generating Phantom ---\")\n",
    "phantom = shepp_logan_phantom()\n",
    "phantom_resized = resize(phantom, (IMAGE_SIZE, IMAGE_SIZE), anti_aliasing=True)\n",
    "phantom_tensor = torch.from_numpy(phantom_resized).float().to(device)\n",
    "phantom_complex = phantom_tensor.to(torch.complex64) # NUFFT expects complex input\n",
    "\n",
    "# Display phantom\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(phantom_tensor.cpu().numpy(), cmap='gray')\n",
    "plt.title(f\"Original Phantom ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Generate K-Space Trajectory ---\n",
    "print(\"\\n--- Generating K-Space Trajectory ---\")\n",
    "# The import for generate_radial_trajectory_2d was updated by the previous subtask to be from iternufft\n",
    "# This script will use that updated import.\n",
    "try:\n",
    "    from iternufft import generate_radial_trajectory_2d\n",
    "    k_trajectory = generate_radial_trajectory_2d(\n",
    "        num_spokes=N_SPOKES,\n",
    "        samples_per_spoke=N_SAMPLES_PER_SPOKE,\n",
    "        device=device\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Failed to import generate_radial_trajectory_2d from iternufft. Trajectory generation will fail.\")\n",
    "    print(\"Make sure iternufft.py is in the PYTHONPATH or the same directory.\")\n",
    "    k_trajectory = torch.zeros((N_SPOKES * N_SAMPLES_PER_SPOKE, 2), device=device) # Placeholder\n",
    "\n",
    "# Display trajectory\n",
    "plt.figure(figsize=(5, 5))\n",
    "if k_trajectory.shape[0] > 0:\n",
    "    plt.scatter(k_trajectory[:, 0].cpu().numpy(), k_trajectory[:, 1].cpu().numpy(), s=0.5)\n",
    "plt.title(f\"K-Space Trajectory ({N_SPOKES} spokes, {N_SAMPLES_PER_SPOKE} samples/spoke)\")\n",
    "plt.xlabel(\"kx\")\n",
    "plt.ylabel(\"ky\")\n",
    "plt.axis('square')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Setup NUFFT Operator for Simulation (no explicit DCF for forward) ---\n",
    "print(\"\\n--- Setting up NUFFT for Simulation ---\")\n",
    "# Standard NUFFT parameters (can be adjusted)\n",
    "# These should be appropriate for NUFFT2D from reconlib.nufft\n",
    "nufft_params_sim = {\n",
    "    'image_shape': (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    'k_trajectory': k_trajectory,\n",
    "    'oversamp_factor': (2.0, 2.0), # Standard oversampling\n",
    "    'kb_J': (4, 4),             # Kaiser-Bessel kernel width\n",
    "    'kb_alpha': (2.34 * 4, 2.34 * 4), # Kaiser-Bessel alpha (beta = pi * sqrt(J^2/os^2 * (os-0.5)^2 - 0.8) )\n",
    "                                     # A common heuristic is alpha = 2.34 * J for os=2\n",
    "    'Ld': (1024, 1024), # More typical table length for KB interpolation\n",
    "    'kb_m': (0.0, 0.0), # Order of KB kernel\n",
    "    'device': device\n",
    "    # No density_comp_weights needed for forward simulation\n",
    "}\n",
    "\n",
    "# Ensure NUFFT2D is imported correctly from reconlib.nufft\n",
    "try:\n",
    "    nufft_op_sim = NUFFT2D(**nufft_params_sim)\n",
    "    print(\"NUFFT2D operator for simulation created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating NUFFT2D operator: {e}\")\n",
    "    nufft_op_sim = None\n",
    "\n",
    "\n",
    "# --- 4. Simulate K-Space Data ---\n",
    "print(\"\\n--- Simulating K-Space Data ---\")\n",
    "if nufft_op_sim is not None:\n",
    "    k_space_data_clean = nufft_op_sim.forward(phantom_complex)\n",
    "    print(f\"Clean k-space data shape: {k_space_data_clean.shape}\")\n",
    "\n",
    "    # Add complex Gaussian noise\n",
    "    noise_level_real = 0.02 # Percentage of max signal amplitude for std dev\n",
    "    noise_std_real = noise_level_real * torch.max(torch.abs(k_space_data_clean))\n",
    "    \n",
    "    # Generate noise for real and imaginary parts separately\n",
    "    noise_r = torch.randn_like(k_space_data_clean.real) * noise_std_real\n",
    "    noise_i = torch.randn_like(k_space_data_clean.imag) * noise_std_real\n",
    "    complex_noise = torch.complex(noise_r, noise_i).to(device)\n",
    "    \n",
    "    k_space_data_noisy = k_space_data_clean + complex_noise\n",
    "    print(f\"Noisy k-space data shape: {k_space_data_noisy.shape}\")\n",
    "\n",
    "    # Store key variables for later cells\n",
    "    # %store phantom_complex k_trajectory k_space_data_noisy IMAGE_SIZE device\n",
    "else:\n",
    "    print(\"NUFFT simulation operator not available. Cannot simulate k-space data.\")\n",
    "    # Create placeholders if simulation failed\n",
    "    k_space_data_clean = torch.zeros((k_trajectory.shape[0]), dtype=torch.complex64, device=device)\n",
    "    k_space_data_noisy = torch.zeros((k_trajectory.shape[0]), dtype=torch.complex64, device=device)\n",
    "\n",
    "# Display k-space data magnitude (log scale)\n",
    "plt.figure(figsize=(6, 5))\n",
    "if k_space_data_noisy.numel() > 0:\n",
    "    plt.scatter(k_trajectory[:,0].cpu(), k_trajectory[:,1].cpu(), c=torch.log(torch.abs(k_space_data_noisy.cpu()) + 1e-9), s=1, cmap='viridis')\n",
    "    plt.colorbar(label=\"log|k-space data|\")\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"K-space data not generated\", ha='center', va='center')\n",
    "plt.title(\"Simulated K-Space Data (Log Magnitude)\")\n",
    "plt.xlabel(\"kx\")\n",
    "plt.ylabel(\"ky\")\n",
    "plt.axis('square')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Data Generation Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Voronoi Weights\n",
    "\n",
    "Here, we calculate the density compensation factors (DCF) using Voronoi tessellation. Each k-space sample point is considered a generator site for a Voronoi cell. The area (in 2D) or volume (in 3D) of this cell is inversely proportional to the local sampling density. The DCF is typically taken as the reciprocal of this area/volume.\n",
    "\n",
    "We use the `compute_voronoi_density_weights_pytorch` function from `reconlib.voronoi.density_weights_pytorch`. This function requires the k-space sample locations (`points`) and the `bounds` of the k-space region being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Voronoi Weights ---\n",
    "print(\"\\n--- Computing Voronoi Weights ---\")\n",
    "\n",
    "# Define bounds for Voronoi tessellation\n",
    "# k_trajectory is expected to be normalized between -0.5 and 0.5 in each dimension.\n",
    "voronoi_bounds = torch.tensor([[-0.5, -0.5], [0.5, 0.5]], dtype=torch.float32, device=device)\n",
    "\n",
    "# Ensure k_trajectory is on the correct device and is float32 for Voronoi computation.\n",
    "# It should already be from the previous cell, but as a safeguard:\n",
    "k_trajectory_voronoi = k_trajectory.to(device=device, dtype=torch.float32)\n",
    "\n",
    "try:\n",
    "    # The import for compute_voronoi_density_weights was updated by a previous subtask\n",
    "    # to be compute_voronoi_density_weights_pytorch\n",
    "    from reconlib.voronoi.density_weights_pytorch import compute_voronoi_density_weights_pytorch\n",
    "    \n",
    "    print(f\"Computing Voronoi weights for {k_trajectory_voronoi.shape[0]} points...\")\n",
    "    # The function in density_weights_pytorch.py is named compute_voronoi_density_weights_pytorch\n",
    "    voronoi_weights = compute_voronoi_density_weights_pytorch(\n",
    "        points=k_trajectory_voronoi,\n",
    "        bounds=voronoi_bounds,\n",
    "        space_dim=2\n",
    "    )\n",
    "    print(f\"Computed Voronoi weights. Shape: {voronoi_weights.shape}, Sum: {torch.sum(voronoi_weights):.4f}\")\n",
    "    \n",
    "    # Ensure weights are positive, as expected for DCF\n",
    "    if torch.any(voronoi_weights <= 0):\n",
    "        print(\"Warning: Some Voronoi weights are not positive. Clamping to a small positive value.\")\n",
    "        voronoi_weights = torch.clamp(voronoi_weights, min=1e-9) # Ensure positive for sqrt later if needed by some algos\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Failed to import compute_voronoi_density_weights_pytorch. Voronoi weights cannot be computed.\")\n",
    "    voronoi_weights = torch.ones(k_trajectory.shape[0], dtype=torch.float32, device=device) / k_trajectory.shape[0] # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"Error computing Voronoi weights: {e}\")\n",
    "    print(\"Using placeholder weights (uniform).\")\n",
    "    voronoi_weights = torch.ones(k_trajectory.shape[0], dtype=torch.float32, device=device) / k_trajectory.shape[0] # Placeholder\n",
    "\n",
    "\n",
    "# Visualize Voronoi weights\n",
    "plt.figure(figsize=(6, 5))\n",
    "if k_trajectory.shape[0] > 0 and voronoi_weights.numel() == k_trajectory.shape[0]:\n",
    "    # Use log of weights for better visualization if range is large\n",
    "    scatter = plt.scatter(\n",
    "        k_trajectory[:, 0].cpu().numpy(),\n",
    "        k_trajectory[:, 1].cpu().numpy(),\n",
    "        c=torch.log(voronoi_weights.cpu() + 1e-9), # Add epsilon for log\n",
    "        s=5,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    plt.colorbar(scatter, label=\"log(Voronoi Weights)\")\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"Voronoi weights not computed or incompatible\", ha='center', va='center')\n",
    "\n",
    "plt.title(\"K-Space Trajectory Colored by Log Voronoi Weights\")\n",
    "plt.xlabel(\"kx\")\n",
    "plt.ylabel(\"ky\")\n",
    "plt.axis('square')\n",
    "plt.show()\n",
    "\n",
    "# %store voronoi_weights # Optional: store for use in later sessions if notebook is split\n",
    "\n",
    "print(\"\\n--- Voronoi Weight Computation Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a Helper function for NUFFT parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper function for NUFFT parameters ---\n",
    "print(\"\\n--- Defining NUFFT Parameter Helper ---\")\n",
    "\n",
    "def get_nufft_params(current_k_trajectory, current_image_size, current_device, dcf_weights=None):\n",
    "    \"\"\"\n",
    "    Helper function to get a dictionary of NUFFT parameters.\n",
    "    Allows specifying density compensation weights.\n",
    "    Assumes NUFFT2D is to be used.\n",
    "    \"\"\"\n",
    "    base_params = {\n",
    "        'image_shape': (current_image_size, current_image_size),\n",
    "        'k_trajectory': current_k_trajectory,\n",
    "        'oversamp_factor': (2.0, 2.0),\n",
    "        'kb_J': (4, 4),\n",
    "        'kb_alpha': (2.34 * 4, 2.34 * 4), # Standard alpha for J=4, os=2\n",
    "        'Ld': (1024, 1024), # Table length for interpolation\n",
    "        'kb_m': (0.0, 0.0),\n",
    "        'device': current_device\n",
    "    }\n",
    "    if dcf_weights is not None:\n",
    "        base_params['density_comp_weights'] = dcf_weights\n",
    "    return base_params\n",
    "\n",
    "# Test the helper function (optional, for immediate feedback in notebook)\n",
    "# These variables (k_trajectory, IMAGE_SIZE, device, voronoi_weights) must have been defined in previous cells.\n",
    "try:\n",
    "    params_with_dcf = get_nufft_params(k_trajectory, IMAGE_SIZE, device, dcf_weights=voronoi_weights)\n",
    "    print(f\"NUFFT params with DCF: image_shape={params_with_dcf['image_shape']}, \"\n",
    "          f\"density_comp_weights_shape={params_with_dcf['density_comp_weights'].shape if 'density_comp_weights' in params_with_dcf and hasattr(params_with_dcf['density_comp_weights'], 'shape') else 'Not set'}\")\n",
    "    \n",
    "    params_no_dcf = get_nufft_params(k_trajectory, IMAGE_SIZE, device)\n",
    "    print(f\"NUFFT params without DCF: image_shape={params_no_dcf['image_shape']}, \"\n",
    "          f\"density_comp_weights_shape={params_no_dcf['density_comp_weights'].shape if 'density_comp_weights' in params_no_dcf and hasattr(params_no_dcf['density_comp_weights'], 'shape') else 'Not set'}\")\n",
    "    \n",
    "    # Try instantiating NUFFT2D with these params to catch errors early\n",
    "    nufft_op_test_dcf = NUFFT2D(**params_with_dcf)\n",
    "    print(\"Successfully created NUFFT2D with DCF weights using helper.\")\n",
    "    nufft_op_test_no_dcf = NUFFT2D(**params_no_dcf)\n",
    "    print(\"Successfully created NUFFT2D without DCF weights using helper.\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"A required variable (k_trajectory, IMAGE_SIZE, device, or voronoi_weights) might not be defined yet: {e}\")\n",
    "    print(\"This cell should be run after the data generation and Voronoi weights cells.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during NUFFT parameter helper function test: {e}\")\n",
    "\n",
    "print(\"\\n--- NUFFT Parameter Helper Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b Method 1: Conjugate Gradient with Voronoi Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Method 1: Conjugate Gradient with Voronoi Weights ---\n",
    "print(\"\\n--- Running Reconstruction Method 1: CG with Voronoi Weights ---\")\n",
    "\n",
    "# Parameters for CG reconstruction\n",
    "cg_iters = 20 # Number of conjugate gradient iterations\n",
    "cg_tol = 1e-6 # Tolerance for CG convergence\n",
    "\n",
    "# Ensure necessary variables from previous cells are available\n",
    "try:\n",
    "    if 'k_space_data_noisy' not in globals() or \\\n",
    "       'k_trajectory' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'voronoi_weights' not in globals() or \\\n",
    "       'get_nufft_params' not in globals() or \\\n",
    "       'NUFFT2D' not in globals() or \\\n",
    "       'conjugate_gradient_reconstruction' not in globals():\n",
    "        raise NameError(\"One or more required variables or functions are not defined. Please run previous cells.\")\n",
    "\n",
    "    # 1. Get NUFFT parameters with Voronoi weights\n",
    "    nufft_params_voronoi = get_nufft_params(\n",
    "        current_k_trajectory=k_trajectory,\n",
    "        current_image_size=IMAGE_SIZE,\n",
    "        current_device=device,\n",
    "        dcf_weights=voronoi_weights\n",
    "    )\n",
    "    print(\"NUFFT parameters for Voronoi-weighted CG obtained.\")\n",
    "\n",
    "    # 2. Instantiate NUFFT2D operator\n",
    "    nufft_op_voronoi = NUFFT2D(**nufft_params_voronoi)\n",
    "    print(\"NUFFT2D operator with Voronoi weights created.\")\n",
    "\n",
    "    # 3. Perform Conjugate Gradient reconstruction\n",
    "    print(f\"Starting Voronoi-weighted CG reconstruction (iters={cg_iters}, tol={cg_tol:.1e})...\")\n",
    "    recon_cg_voronoi = conjugate_gradient_reconstruction(\n",
    "        kspace_data=k_space_data_noisy,\n",
    "        # sampling_points is part of nufft_params_voronoi and handled by NUFFT2D init\n",
    "        # image_shape is part of nufft_params_voronoi and handled by NUFFT2D init\n",
    "        nufft_operator_class=NUFFT2D, # Pass the class itself\n",
    "        nufft_kwargs=nufft_params_voronoi, # Pass the dict of args for NUFFT2D\n",
    "        # use_voronoi flag in conjugate_gradient_reconstruction is not strictly needed\n",
    "        # if density_comp_weights are directly in nufft_kwargs, but set for clarity\n",
    "        use_voronoi=True, \n",
    "        voronoi_weights=voronoi_weights, # Redundant if in nufft_kwargs, but doesn't hurt\n",
    "        max_iters=cg_iters,\n",
    "        tol=cg_tol\n",
    "    )\n",
    "    print(\"Voronoi-weighted CG reconstruction complete.\")\n",
    "    print(f\"Reconstructed image shape: {recon_cg_voronoi.shape}\")\n",
    "\n",
    "    # 4. Display the reconstructed image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_cg_voronoi.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(f\"Recon: CG with Voronoi Weights ({cg_iters} iters)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # %store recon_cg_voronoi # Optional\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Ensure all previous cells have been run successfully.\")\n",
    "    recon_cg_voronoi = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Voronoi-weighted CG reconstruction: {e}\")\n",
    "    recon_cg_voronoi = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "\n",
    "print(\"\\n--- CG with Voronoi Weights Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c Method 2: Simple Gridding (Adjoint NUFFT with default/no explicit DCF)\n",
    "\n",
    "This is the most basic reconstruction approach. It involves applying the adjoint NUFFT operation directly to the (noisy) k-space data. The `NUFFT2D` operator, when initialized without explicit `density_comp_weights`, might use a simple internal default DCF (like a radial ramp for radial data) or no DCF at all, depending on its implementation. This method is fast but often yields images with density-related artifacts and lower quality compared to iterative methods with accurate DCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Method 2: Simple Gridding (Adjoint NUFFT with default/no explicit DCF) ---\n",
    "print(\"\\n--- Running Reconstruction Method 2: Simple Gridding ---\")\n",
    "\n",
    "try:\n",
    "    if 'k_space_data_noisy' not in globals() or \\\n",
    "       'k_trajectory' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'get_nufft_params' not in globals() or \\\n",
    "       'NUFFT2D' not in globals():\n",
    "        raise NameError(\"One or more required variables or functions are not defined. Please run previous cells.\")\n",
    "\n",
    "    # 1. Get NUFFT parameters *without* explicit DCF weights\n",
    "    # This will rely on NUFFT2D's default behavior (e.g., simple radial DCF or none)\n",
    "    nufft_params_basic = get_nufft_params(\n",
    "        current_k_trajectory=k_trajectory,\n",
    "        current_image_size=IMAGE_SIZE,\n",
    "        current_device=device,\n",
    "        dcf_weights=None # Explicitly None\n",
    "    )\n",
    "    print(\"NUFFT parameters for simple gridding (default DCF) obtained.\")\n",
    "\n",
    "    # 2. Instantiate NUFFT2D operator\n",
    "    nufft_op_basic = NUFFT2D(**nufft_params_basic)\n",
    "    print(\"NUFFT2D operator for simple gridding created.\")\n",
    "\n",
    "    # 3. Perform reconstruction using simple adjoint (gridding)\n",
    "    print(\"Starting simple gridding (adjoint NUFFT)...\")\n",
    "    # The adjoint of NUFFT2D applies its internally estimated DCF if no density_comp_weights were passed at init.\n",
    "    recon_gridding = nufft_op_basic.adjoint(k_space_data_noisy)\n",
    "    print(\"Simple gridding complete.\")\n",
    "    print(f\"Reconstructed image shape: {recon_gridding.shape}\")\n",
    "\n",
    "    # 4. Display the reconstructed image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_gridding.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(\"Recon: Simple Gridding (Adjoint NUFFT)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # %store recon_gridding # Optional\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Ensure all previous cells have been run successfully.\")\n",
    "    recon_gridding = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during simple gridding reconstruction: {e}\")\n",
    "    recon_gridding = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "\n",
    "print(\"\\n--- Simple Gridding Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.d Method 3: Conjugate Gradient with default/no explicit DCF\n",
    "\n",
    "This method uses the Conjugate Gradient algorithm to iteratively solve the least-squares problem: `argmin_x ||Ax - y||^2`, where `A` is the NUFFT operator (using its default internal DCF, if any, as no explicit Voronoi weights are provided) and `y` is the noisy k-space data. This should improve upon simple gridding but might not perform as well as CG with more accurate (Voronoi) DCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Method 3: Conjugate Gradient with default/no explicit DCF ---\n",
    "print(\"\\n--- Running Reconstruction Method 3: CG with Default/No Explicit DCF ---\")\n",
    "\n",
    "# Parameters for CG reconstruction (can be same as for Voronoi CG)\n",
    "cg_iters_basic = 20 # Number of conjugate gradient iterations\n",
    "cg_tol_basic = 1e-6 # Tolerance for CG convergence\n",
    "\n",
    "try:\n",
    "    if 'k_space_data_noisy' not in globals() or \\\n",
    "       'k_trajectory' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'get_nufft_params' not in globals() or \\\n",
    "       'NUFFT2D' not in globals() or \\\n",
    "       'conjugate_gradient_reconstruction' not in globals():\n",
    "        raise NameError(\"One or more required variables or functions are not defined. Please run previous cells.\")\n",
    "\n",
    "    # 1. Get NUFFT parameters *without* explicit DCF weights\n",
    "    nufft_params_cg_basic = get_nufft_params(\n",
    "        current_k_trajectory=k_trajectory,\n",
    "        current_image_size=IMAGE_SIZE,\n",
    "        current_device=device,\n",
    "        dcf_weights=None # Explicitly None for default NUFFT DCF behavior\n",
    "    )\n",
    "    print(\"NUFFT parameters for CG with default DCF obtained.\")\n",
    "\n",
    "    # 2. Instantiate NUFFT2D operator\n",
    "    # NUFFT2D's adjoint will use its internal default DCF if density_comp_weights is None\n",
    "    nufft_op_cg_basic = NUFFT2D(**nufft_params_cg_basic)\n",
    "    print(\"NUFFT2D operator for CG with default DCF created.\")\n",
    "\n",
    "    # 3. Perform Conjugate Gradient reconstruction\n",
    "    print(f\"Starting CG reconstruction with default DCF (iters={cg_iters_basic}, tol={cg_tol_basic:.1e})...\")\n",
    "    recon_cg_basic_dcf = conjugate_gradient_reconstruction(\n",
    "        kspace_data=k_space_data_noisy,\n",
    "        nufft_operator_class=NUFFT2D,\n",
    "        nufft_kwargs=nufft_params_cg_basic, # These kwargs do NOT include explicit Voronoi weights\n",
    "        use_voronoi=False, # Explicitly False\n",
    "        voronoi_weights=None, # Explicitly None\n",
    "        max_iters=cg_iters_basic,\n",
    "        tol=cg_tol_basic\n",
    "    )\n",
    "    print(\"CG reconstruction with default DCF complete.\")\n",
    "    print(f\"Reconstructed image shape: {recon_cg_basic_dcf.shape}\")\n",
    "\n",
    "    # 4. Display the reconstructed image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(torch.abs(recon_cg_basic_dcf.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(f\"Recon: CG with Default DCF ({cg_iters_basic} iters)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # %store recon_cg_basic_dcf # Optional\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Ensure all previous cells have been run successfully.\")\n",
    "    recon_cg_basic_dcf = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during CG reconstruction with default DCF: {e}\")\n",
    "    recon_cg_basic_dcf = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "\n",
    "print(\"\\n--- CG with Default DCF Cell Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize and Compare Results\n",
    "\n",
    "Finally, we display the original phantom and the images reconstructed by the three different methods. Visual inspection helps in qualitatively assessing the impact of different reconstruction strategies and density compensation techniques. We also compute quantitative metrics (MSE, PSNR, SSIM) to provide an objective measure of reconstruction fidelity against the original phantom. Lower MSE, higher PSNR, and SSIM closer to 1 indicate better reconstruction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Visualize and Compare Results ---\n",
    "print(\"\\n--- Visualizing and Comparing Reconstruction Results ---\")\n",
    "\n",
    "try:\n",
    "    # Ensure all required variables are defined from previous cells\n",
    "    if 'phantom_complex' not in globals() or \\\n",
    "       'recon_cg_voronoi' not in globals() or \\\n",
    "       'recon_gridding' not in globals() or \\\n",
    "       'recon_cg_basic_dcf' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals():\n",
    "        raise NameError(\"One or more required reconstruction results or variables are not defined. Please run all previous cells.\")\n",
    "\n",
    "    # Prepare original phantom for comparison (use absolute value, as NUFFT output is complex)\n",
    "    original_phantom_abs = torch.abs(phantom_complex.cpu())\n",
    "\n",
    "    # Prepare reconstructed images (use absolute values)\n",
    "    recon_cg_voronoi_abs = torch.abs(recon_cg_voronoi.cpu())\n",
    "    recon_gridding_abs = torch.abs(recon_gridding.cpu())\n",
    "    recon_cg_basic_dcf_abs = torch.abs(recon_cg_basic_dcf.cpu())\n",
    "    \n",
    "    reconstructions = {\n",
    "        \"Original Phantom\": original_phantom_abs,\n",
    "        \"CG + Voronoi Weights\": recon_cg_voronoi_abs,\n",
    "        \"Simple Gridding (Adjoint)\": recon_gridding_abs,\n",
    "        \"CG + Default/No DCF\": recon_cg_basic_dcf_abs\n",
    "    }\n",
    "\n",
    "    # --- Plotting Side-by-Side ---\n",
    "    num_images = len(reconstructions)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 4, 4))\n",
    "    fig.suptitle(\"Comparison of Reconstruction Methods\", fontsize=16)\n",
    "\n",
    "    for i, (title, img) in enumerate(reconstructions.items()):\n",
    "        ax = axes[i]\n",
    "        im = ax.imshow(img.numpy(), cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        # fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04) # Optional colorbar per image\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
    "    plt.show()\n",
    "\n",
    "    # --- Quantitative Comparison (Optional: MSE, PSNR) ---\n",
    "    print(\"\\n--- Quantitative Metrics (vs Original Phantom) ---\")\n",
    "    try:\n",
    "        from reconlib.metrics.image_metrics import mse, psnr, ssim # Assuming these are available\n",
    "        \n",
    "        # Ensure original_phantom_abs is on the same device as recons if metrics require it,\n",
    "        # but typically metrics are computed on CPU tensors.\n",
    "        # The images are already .cpu().numpy() or .cpu() above.\n",
    "\n",
    "        data_range = original_phantom_abs.max() - original_phantom_abs.min()\n",
    "        if data_range == 0: data_range = 1.0 # Avoid division by zero if phantom is flat\n",
    "        \n",
    "        print(f\"{'Method':<30} | {'MSE':<10} | {'PSNR (dB)':<10} | {'SSIM':<10}\")\n",
    "        print(\"-\" * 65)\n",
    "\n",
    "        for title, recon_img_abs in reconstructions.items():\n",
    "            if title == \"Original Phantom\":\n",
    "                continue # Skip comparing original to itself for these metrics\n",
    "\n",
    "            # Ensure recon_img_abs is also a CPU tensor for metric functions\n",
    "            current_mse = mse(original_phantom_abs, recon_img_abs).item()\n",
    "            current_psnr = psnr(original_phantom_abs, recon_img_abs, data_range=data_range).item()\n",
    "            # For SSIM, ensure images are suitable (e.g., data_range, potentially normalize if needed by specific SSIM impl)\n",
    "            # ssim function in reconlib.metrics.image_metrics expects PyTorch tensors.\n",
    "            current_ssim = ssim(original_phantom_abs.unsqueeze(0).unsqueeze(0), # Add batch/channel for some SSIM versions\n",
    "                                recon_img_abs.unsqueeze(0).unsqueeze(0), \n",
    "                                data_range=data_range,\n",
    "                                gaussian_kernel=True, # Common default\n",
    "                                kernel_size=7 # Common default\n",
    "                               ).item()\n",
    "\n",
    "            print(f\"{title:<30} | {current_mse:<10.4e} | {current_psnr:<10.2f} | {current_ssim:<10.4f}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"reconlib.metrics.image_metrics not found. Skipping quantitative metrics.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "        \n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Ensure all previous cells have been run successfully to generate reconstruction variables.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during visualization or comparison: {e}\")\n",
    "\n",
    "print(\"\\n--- Visualization and Comparison Cell Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
