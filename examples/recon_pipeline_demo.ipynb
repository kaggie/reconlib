{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReconLib Self-Contained NUFFT Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the use of the self-contained NUFFT implementation within ReconLib for both 2D and 3D MRI reconstruction. It showcases the `NUFFTOperator` using the internal Python-based NUFFT (table-based method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline \n",
    "\n",
    "# ReconLib imports\n",
    "from reconlib.operators import NUFFTOperator\n",
    "\n",
    "# Helper functions from local scripts (assuming they are in python path or same directory)\n",
    "# If ReconLib is installed, these might be part of the library, adjust path if necessary\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..'))) # Add parent directory to path to find iternufft and l1l2recon\n",
    "\n",
    "from iternufft import iterative_recon, generate_phantom_2d, generate_radial_trajectory_2d, generate_phantom_3d, generate_radial_trajectory_3d\n",
    "from l1l2recon import L1Reconstruction, L2Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 2D Reconstruction Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Phantom and Trajectory (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx_2d, Ny_2d = 128, 128\n",
    "image_shape_2d = (Nx_2d, Ny_2d)\n",
    "\n",
    "phantom_2d = generate_phantom_2d(Nx_2d, device=device).to(torch.complex64)\n",
    "k_traj_2d = generate_radial_trajectory_2d(num_spokes=128, samples_per_spoke=256, device=device)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_2d.abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title('Original 2D Phantom')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].scatter(k_traj_2d[:, 0].cpu().numpy(), k_traj_2d[:, 1].cpu().numpy(), s=0.5)\n",
    "axs[1].set_title('2D Radial K-space Trajectory')\n",
    "axs[1].set_xlabel('kx')\n",
    "axs[1].set_ylabel('ky')\n",
    "axs[1].set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. NUFFTOperator Setup (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_factor_2d = (2.0, 2.0)\n",
    "kb_J_2d = (4, 4)\n",
    "kb_alpha_2d = tuple(2.34 * J_d for J_d in kb_J_2d) # Common heuristic for alpha\n",
    "Ld_2d = (2**10, 2**10)\n",
    "Kd_2d = tuple(int(N * os) for N, os in zip(image_shape_2d, oversamp_factor_2d))\n",
    "# kb_m_2d and n_shift_2d will use defaults in NUFFTOperator if not passed (or pass explicitly)\n",
    "\n",
    "nufft_op_2d = NUFFTOperator(k_trajectory=k_traj_2d, \n",
    "                            image_shape=image_shape_2d, \n",
    "                            oversamp_factor=oversamp_factor_2d, \n",
    "                            kb_J=kb_J_2d, \n",
    "                            kb_alpha=kb_alpha_2d, \n",
    "                            Ld=Ld_2d,\n",
    "                            Kd=Kd_2d, # Optional, NUFFTOperator can compute this\n",
    "                            kb_m=(0.0, 0.0), # Explicitly setting MIRT default for m\n",
    "                            n_shift=(0.0, 0.0), # Explicitly setting MIRT default for n_shift\n",
    "                            device=device)\n",
    "print(\"NUFFTOperator for 2D created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Simulate K-Space Data (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulating 2D k-space data...\")\n",
    "kspace_data_2d = nufft_op_2d.op(phantom_2d)\n",
    "\n",
    "# Add a small amount of Gaussian noise\n",
    "noise_level_2d = 0.01 * torch.mean(torch.abs(kspace_data_2d)) \n",
    "kspace_data_2d_noisy = kspace_data_2d + noise_level_2d * (torch.randn_like(kspace_data_2d.real) + 1j * torch.randn_like(kspace_data_2d.real))\n",
    "print(\"Noisy 2D k-space data generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Iterative Reconstruction (CG - 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 2D iterative reconstruction (CG)...\")\n",
    "recon_img_2d_cg = iterative_recon(kspace_data=kspace_data_2d_noisy, \n",
    "                                  nufft_op=nufft_op_2d, \n",
    "                                  num_iters=10)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_2d.abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title('Original 2D Phantom')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_2d_cg.abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title('Reconstructed 2D Image (CG)')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. L2 Reconstruction (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 2D L2 reconstruction...\")\n",
    "l2_recon_module_2d = L2Reconstruction(linear_operator=nufft_op_2d, num_iterations=15, learning_rate=0.1)\n",
    "recon_img_2d_l2 = l2_recon_module_2d.forward(kspace_data_2d_noisy)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_2d.abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title('Original 2D Phantom')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_2d_l2.abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title('Reconstructed 2D Image (L2)')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. L1 Reconstruction (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 2D L1 reconstruction...\")\n",
    "l1_recon_module_2d = L1Reconstruction(linear_operator=nufft_op_2d, num_iterations=20, lambda_reg=0.001, learning_rate=0.1)\n",
    "recon_img_2d_l1 = l1_recon_module_2d.forward(kspace_data_2d_noisy)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_2d.abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title('Original 2D Phantom')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_2d_l1.abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title('Reconstructed 2D Image (L1)')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D Reconstruction Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Phantom and Trajectory (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz_3d, Ny_3d, Nx_3d = 32, 32, 32\n",
    "image_shape_3d = (Nz_3d, Ny_3d, Nx_3d)\n",
    "\n",
    "phantom_3d = generate_phantom_3d(shape=image_shape_3d, device=device).to(torch.complex64)\n",
    "k_traj_3d = generate_radial_trajectory_3d(num_profiles_z=32, \n",
    "                                        num_spokes_per_profile=32, \n",
    "                                        samples_per_spoke=32, \n",
    "                                        shape=image_shape_3d, \n",
    "                                        device=device)\n",
    "\n",
    "# Plot center slice of 3D phantom\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax1.imshow(phantom_3d[Nz_3d // 2, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "ax1.set_title(f'Original 3D Phantom (Slice {Nz_3d // 2})')\n",
    "ax1.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot 3D k-space trajectory (subset for clarity)\n",
    "fig2 = plt.figure(figsize=(6,6))\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "num_points_to_plot = min(k_traj_3d.shape[0], 2000) # Plot up to 2000 points\n",
    "ax2.scatter(k_traj_3d[:num_points_to_plot, 0].cpu().numpy(), \n",
    "            k_traj_3d[:num_points_to_plot, 1].cpu().numpy(), \n",
    "            k_traj_3d[:num_points_to_plot, 2].cpu().numpy(), s=0.5)\n",
    "ax2.set_title('3D Stack-of-Stars K-space Trajectory (Subset)')\n",
    "ax2.set_xlabel('kx')\n",
    "ax2.set_ylabel('ky')\n",
    "ax2.set_zlabel('kz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. NUFFTOperator Setup (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_factor_3d = (1.5, 1.5, 1.5) # Reduced for speed/memory\n",
    "kb_J_3d = (4, 4, 4)\n",
    "kb_alpha_3d = tuple(2.34 * J_d for J_d in kb_J_3d)\n",
    "Ld_3d = (2**8, 2**8, 2**8) # Reduced for speed/memory\n",
    "Kd_3d = tuple(int(N * os) for N, os in zip(image_shape_3d, oversamp_factor_3d))\n",
    "n_shift_3d = (0.0, 0.0, 0.0)\n",
    "kb_m_3d = (0.0,0.0,0.0)\n",
    "\n",
    "nufft_op_3d = NUFFTOperator(k_trajectory=k_traj_3d, \n",
    "                            image_shape=image_shape_3d, \n",
    "                            oversamp_factor=oversamp_factor_3d, \n",
    "                            kb_J=kb_J_3d, \n",
    "                            kb_alpha=kb_alpha_3d, \n",
    "                            Ld=Ld_3d,\n",
    "                            Kd=Kd_3d,\n",
    "                            kb_m=kb_m_3d,\n",
    "                            n_shift=n_shift_3d, \n",
    "                            device=device, \n",
    "                            nufft_type_3d='table') # Explicitly use table-based NUFFT\n",
    "print(\"NUFFTOperator for 3D (table-based, linear interpolation) created: nufft_op_3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrating NUFFT with Nearest Neighbor Interpolation\n",
    "We can also choose `interpolation_order=0` for nearest neighbor interpolation in the table lookup, which might be faster but less accurate than linear interpolation (`order=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same parameters as nufft_op_3d, but with interpolation_order=0\n",
    "nufft_op_3d_nn = NUFFTOperator(k_trajectory=k_traj_3d, \n",
    "                               image_shape=image_shape_3d, \n",
    "                               oversamp_factor=oversamp_factor_3d, \n",
    "                               kb_J=kb_J_3d, \n",
    "                               kb_alpha=kb_alpha_3d, \n",
    "                               Ld=Ld_3d,\n",
    "                               Kd=Kd_3d,\n",
    "                               kb_m=kb_m_3d,\n",
    "                               n_shift=n_shift_3d, \n",
    "                               interpolation_order=0, # Specify Nearest Neighbor\n",
    "                               device=device, \n",
    "                               nufft_type_3d='table')\n",
    "print(\"NUFFTOperator for 3D (Nearest Neighbor Interpolation) created: nufft_op_3d_nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Simulate K-Space Data (3D - Linear Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulating 3D k-space data (using linear interpolation NUFFT)...\")\n",
    "kspace_data_3d = nufft_op_3d.op(phantom_3d)\n",
    "\n",
    "# Add a small amount of Gaussian noise\n",
    "noise_level_3d = 0.01 * torch.mean(torch.abs(kspace_data_3d))\n",
    "kspace_data_3d_noisy = kspace_data_3d + noise_level_3d * (torch.randn_like(kspace_data_3d.real) + 1j * torch.randn_like(kspace_data_3d.real))\n",
    "print(\"Noisy 3D k-space data (linear interp) generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.2. Simulate K-Space Data (3D - Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulating 3D k-space data (using nearest neighbor NUFFT)...\")\n",
    "kspace_data_3d_nn = nufft_op_3d_nn.op(phantom_3d)\n",
    "\n",
    "# Add the same level of Gaussian noise for fair comparison\n",
    "kspace_data_3d_nn_noisy = kspace_data_3d_nn + noise_level_3d * (torch.randn_like(kspace_data_3d_nn.real) + 1j * torch.randn_like(kspace_data_3d_nn.real))\n",
    "print(\"Noisy 3D k-space data (nearest neighbor) generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Iterative Reconstruction (CG - 3D - Linear Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 3D iterative reconstruction (CG - Linear Interpolation)...\")\n",
    "recon_img_3d_cg = iterative_recon(kspace_data=kspace_data_3d_noisy, \n",
    "                                  nufft_op=nufft_op_3d, \n",
    "                                  num_iters=5) # Reduced iterations for speed\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "center_slice_idx = image_shape_3d[0] // 2\n",
    "axs[0].imshow(phantom_3d[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title(f'Original 3D Phantom (Slice {center_slice_idx})')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_3d_cg[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title(f'Reconstructed 3D (CG - Linear) (Slice {center_slice_idx})')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.2. Iterative Reconstruction (CG - 3D - Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 3D iterative reconstruction (CG - Nearest Neighbor)...\")\n",
    "recon_img_3d_cg_nn = iterative_recon(kspace_data=kspace_data_3d_nn_noisy, \n",
    "                                     nufft_op=nufft_op_3d_nn, \n",
    "                                     num_iters=5) # Reduced iterations for speed\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_3d[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title(f'Original 3D Phantom (Slice {center_slice_idx})')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_3d_cg_nn[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title(f'Reconstructed 3D (CG - NN) (Slice {center_slice_idx})')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. L2 Reconstruction (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 3D L2 reconstruction...\")\n",
    "l2_recon_module_3d = L2Reconstruction(linear_operator=nufft_op_3d, num_iterations=10, learning_rate=0.1)\n",
    "recon_img_3d_l2 = l2_recon_module_3d.forward(kspace_data_3d_noisy)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_3d[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title(f'Original 3D Phantom (Slice {center_slice_idx})')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_3d_l2[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title(f'Reconstructed 3D (L2) (Slice {center_slice_idx})')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. L1 Reconstruction (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 3D L1 reconstruction...\")\n",
    "l1_recon_module_3d = L1Reconstruction(linear_operator=nufft_op_3d, num_iterations=15, lambda_reg=0.005, learning_rate=0.1)\n",
    "recon_img_3d_l1 = l1_recon_module_3d.forward(kspace_data_3d_noisy)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(phantom_3d[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[0].set_title(f'Original 3D Phantom (Slice {center_slice_idx})')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(recon_img_3d_l1[center_slice_idx, :, :].abs().cpu().numpy(), cmap='gray')\n",
    "axs[1].set_title(f'Reconstructed 3D (L1) (Slice {center_slice_idx})')\n",
    "axs[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrated the use of `NUFFTOperator` with the self-contained Python-based (table method) NUFFT engine for both 2D and 3D MRI reconstruction scenarios. It showcased iterative reconstruction using Conjugate Gradient (from `iternufft.py`) and L2/L1 regularized reconstructions (from `l1l2recon.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adjointness Test\n",
    "\n",
    "The adjoint property of an operator A is defined by the relation `<Ax, y> = <x, A*y>`, where `A*` is the adjoint of A, and `<u,v>` is the inner product (dot product) `sum(u * conj(v))`. This test is crucial for verifying the correctness of the forward and adjoint NUFFT implementations, especially for iterative reconstruction algorithms that rely on this property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Adjointness Test for 2D NUFFTOperator ---\")\n",
    "# Ensure nufft_op_2d and image_shape_2d are available from previous cells\n",
    "\n",
    "# Create random complex data for image domain x_2d and k-space domain y_2d\n",
    "x_2d = torch.randn(image_shape_2d, dtype=torch.complex64, device=device)\n",
    "y_2d_shape = (k_traj_2d.shape[0],) # k-space data is 1D vector of k-space points\n",
    "y_2d = torch.randn(y_2d_shape, dtype=torch.complex64, device=device)\n",
    "\n",
    "# Compute Ax_2d and Aty_2d\n",
    "Ax_2d = nufft_op_2d.op(x_2d)\n",
    "Aty_2d = nufft_op_2d.op_adj(y_2d)\n",
    "\n",
    "# Calculate dot products\n",
    "lhs_2d = torch.sum(Ax_2d * torch.conj(y_2d))\n",
    "rhs_2d = torch.sum(x_2d * torch.conj(Aty_2d))\n",
    "\n",
    "print(f\"LHS (<Ax, y>): {lhs_2d.item()}\")\n",
    "print(f\"RHS (<x, A*y>): {rhs_2d.item()}\")\n",
    "\n",
    "abs_diff_2d = torch.abs(lhs_2d - rhs_2d).item()\n",
    "print(f\"Absolute Difference: {abs_diff_2d}\")\n",
    "\n",
    "if torch.abs(lhs_2d) > 1e-9:\n",
    "    rel_diff_2d = abs_diff_2d / torch.abs(lhs_2d).item()\n",
    "    print(f\"Relative Difference: {rel_diff_2d}\")\n",
    "else:\n",
    "    print(\"LHS is near zero, relative difference is not meaningful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Adjointness Test for 3D NUFFTOperator ---\")\n",
    "# Ensure nufft_op_3d and image_shape_3d are available from previous cells\n",
    "\n",
    "# Create random complex data for image domain x_3d and k-space domain y_3d\n",
    "x_3d = torch.randn(image_shape_3d, dtype=torch.complex64, device=device)\n",
    "y_3d_shape = (k_traj_3d.shape[0],) # k-space data is 1D vector\n",
    "y_3d = torch.randn(y_3d_shape, dtype=torch.complex64, device=device)\n",
    "\n",
    "# Compute Ax_3d and Aty_3d\n",
    "Ax_3d = nufft_op_3d.op(x_3d)\n",
    "Aty_3d = nufft_op_3d.op_adj(y_3d)\n",
    "\n",
    "# Calculate dot products\n",
    "lhs_3d = torch.sum(Ax_3d * torch.conj(y_3d))\n",
    "rhs_3d = torch.sum(x_3d * torch.conj(Aty_3d))\n",
    "\n",
    "print(f\"LHS (<Ax, y>): {lhs_3d.item()}\")\n",
    "print(f\"RHS (<x, A*y>): {rhs_3d.item()}\")\n",
    "\n",
    "abs_diff_3d = torch.abs(lhs_3d - rhs_3d).item()\n",
    "print(f\"Absolute Difference: {abs_diff_3d}\")\n",
    "\n",
    "if torch.abs(lhs_3d) > 1e-9:\n",
    "    rel_diff_3d = abs_diff_3d / torch.abs(lhs_3d).item()\n",
    "    print(f\"Relative Difference: {rel_diff_3d}\")\n",
    "else:\n",
    "    print(\"LHS is near zero, relative difference is not meaningful.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
