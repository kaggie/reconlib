{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PET Reconstruction with OSEM Example\n",
    "\n",
    "This notebook demonstrates a basic PET reconstruction workflow using the Ordered Subsets Expectation Maximization (OSEM) algorithm, along with examples of other PCCT and material decomposition functionalities.\n",
    "1. Generate a simple 2D phantom.\n",
    "2. Define scanner geometry for PET.\n",
    "3. Simulate projection data (sinogram) using a System Matrix, optionally adding Poisson noise.\n",
    "4. Reconstruct the image from the sinogram using the OSEM optimizer.\n",
    "5. Visualize the original phantom, initial guess, and the reconstructed image.\n",
    "6. Demonstrate advanced PCCT detector effects.\n",
    "7. Illustrate projection-domain material decomposition.\n",
    "8. Show statistical image reconstruction (SIR) for PCCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure reconlib is in the Python path (e.g., if running from examples folder)\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from reconlib.modalities.pet import PhantomGenerator, simulate_projection_data # Updated import\n",
    "    from reconlib.modalities.pcct.operators import PCCTProjectorOperator\n",
    "    from reconlib.modalities.pcct.reconstructors import tv_reconstruction_pcct_mu_ref # For PCCT SIR demo\n",
    "    from reconlib.modalities.pcct.material_decomposition import (\n",
    "        MaterialDecompositionForwardOperator, \n",
    "        IterativeMaterialDecompositionReconstructor\n",
    "    )\n",
    "    from reconlib.modalities.pcct.projection_domain_decomposition import (\n",
    "        calculate_material_thickness_sinograms, \n",
    "        reconstruct_thickness_maps_from_sinograms,\n",
    "        LinearRadonOperatorPlaceholder \n",
    "    )\n",
    "    from reconlib.modalities.pcct.utils import get_pcct_energy_scaling_factors, generate_pcct_phantom_material_maps, combine_material_maps_to_mu_ref\n",
    "    from reconlib.geometry import ScannerGeometry, SystemMatrix\n",
    "    from reconlib.optimizers import OrderedSubsetsExpectationMaximization\n",
    "    from reconlib.plotting import plot_projection_data, visualize_reconstruction\n",
    "    # from reconlib.regularizers.common import NonnegativityConstraint # Not used in this version\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}. Make sure reconlib is installed or PYTHONPATH is set correctly.\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PET OSEM Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Phantom Generation (PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_pet = (128, 128)\n",
    "phantom_gen_pet = PhantomGenerator(device=device)\n",
    "try:\n",
    "    phantom_pet = phantom_gen_pet.generate(size=img_size_pet, phantom_type='circles_pet')\n",
    "    print(f\"Generated 'circles_pet' phantom of shape: {phantom_pet.shape}\")\n",
    "except NotImplementedError:\n",
    "    print(\"'circles_pet' not implemented, creating a dummy PET phantom.\")\n",
    "    phantom_pet = torch.zeros(1, 1, *img_size_pet, device=device)\n",
    "    y_coords, x_coords = torch.ogrid[-img_size_pet[0]//2:img_size_pet[0]//2, -img_size_pet[1]//2:img_size_pet[1]//2]\n",
    "    y_coords, x_coords = y_coords.to(device), x_coords.to(device)\n",
    "    mask1 = x_coords*x_coords + y_coords*y_coords <= (min(img_size_pet[0],img_size_pet[1])//3)**2\n",
    "    phantom_pet[0,0][mask1] = 1.0\n",
    "\n",
    "visualize_reconstruction(phantom_pet.squeeze().cpu().numpy(), main_title=\"Original PET Phantom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scanner Geometry Definition (PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_detectors_pet = 180\n",
    "num_angles_pet = 180\n",
    "angles_pet = np.linspace(0, np.pi, num_angles_pet, endpoint=False)\n",
    "scanner_geo_pet = ScannerGeometry(\n",
    "    geometry_type='cylindrical_pet', \n",
    "    angles=angles_pet, \n",
    "    n_detector_pixels=num_detectors_pet, \n",
    "    detector_size=np.array([4.0]),\n",
    "    detector_radius=350.0\n",
    ")\n",
    "print(f\"PET Scanner geometry type: {scanner_geo_pet.geometry_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. System Matrix and Data Simulation (PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_matrix_pet = SystemMatrix(scanner_geometry=scanner_geo_pet, img_size=img_size_pet, device=device)\n",
    "phantom_for_proj_pet = phantom_pet.to(device) # Ensure it's on the right device\n",
    "if phantom_for_proj_pet.ndim == 2: phantom_for_proj_pet = phantom_for_proj_pet.unsqueeze(0).unsqueeze(0)\n",
    "elif phantom_for_proj_pet.ndim == 3: phantom_for_proj_pet = phantom_for_proj_pet.unsqueeze(0)\n",
    "\n",
    "projections_clean_pet = sys_matrix_pet.forward_project(phantom_for_proj_pet)\n",
    "projections_noisy_pet = simulate_projection_data(phantom_for_proj_pet, sys_matrix_pet, noise_model='poisson', intensity_scale=20000)\n",
    "print(f\"Noisy PET projection data shape: {projections_noisy_pet.shape}\")\n",
    "plot_projection_data(projections_noisy_pet.squeeze().cpu().numpy(), title=\"Noisy PET Sinogram (Simulated)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. OSEM Reconstruction (PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_image_pet = torch.ones_like(phantom_for_proj_pet, dtype=torch.float32, device=device) * torch.mean(phantom_for_proj_pet)\n",
    "initial_image_pet[initial_image_pet <= 1e-9] = 1e-9\n",
    "\n",
    "num_iterations_osem = 20\n",
    "num_subsets_osem = 10\n",
    "\n",
    "osem_reconstructor = OrderedSubsetsExpectationMaximization(\n",
    "    system_matrix=sys_matrix_pet, \n",
    "    num_subsets=num_subsets_osem, \n",
    "    num_iterations=num_iterations_osem, \n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "reconstructed_image_osem = osem_reconstructor.solve(\n",
    "    k_space_data=projections_noisy_pet, \n",
    "    forward_op=sys_matrix_pet, \n",
    "    initial_guess=initial_image_pet\n",
    ")\n",
    "print(f\"OSEM Reconstructed image shape: {reconstructed_image_osem.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualization of PET Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "phantom_max_val = phantom_for_proj_pet.max().item()\n",
    "axes[0].imshow(phantom_for_proj_pet.squeeze().cpu().numpy(), cmap='gray', vmin=0, vmax=phantom_max_val)\n",
    "axes[0].set_title('Original PET Phantom'); axes[0].axis('off')\n",
    "axes[1].imshow(initial_image_pet.squeeze().cpu().numpy(), cmap='gray', vmin=0, vmax=initial_image_pet.max().item())\n",
    "axes[1].set_title('Initial PET Image'); axes[1].axis('off')\n",
    "im = axes[2].imshow(reconstructed_image_osem.squeeze().cpu().numpy(), cmap='gray', vmin=0, vmax=reconstructed_image_osem.max().item())\n",
    "axes[2].set_title(f'OSEM PET Recon ({num_iterations_osem} iter, {num_subsets_osem} subsets)'); axes[2].axis('off')\n",
    "fig.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced PCCT Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Advanced Detector Effects Simulation (PCCT)\n",
    "Demonstrates `PCCTProjectorOperator` with spectral broadening and pile-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s_pcct_adv = (64,64)\n",
    "n_angles_pcct_adv = 50 \n",
    "n_dets_pcct_adv = 70\n",
    "energy_bins_pcct_adv = [(20, 50), (50, 80), (80, 120)]\n",
    "I0_pcct_adv = torch.tensor([1e6, 2e6, 1e6], device=device) # Higher I0 for pile-up\n",
    "energy_scales_pcct_adv = get_pcct_energy_scaling_factors(energy_bins_pcct_adv, device=device)\n",
    "\n",
    "true_mu_map_pcct_adv = torch.zeros(img_s_pcct_adv, device=device)\n",
    "true_mu_map_pcct_adv[16:48, 16:48] = 0.02 # Simple phantom\n",
    "\n",
    "adv_effect_config = {\n",
    "    'image_shape': img_s_pcct_adv,\n",
    "    'num_angles': n_angles_pcct_adv,\n",
    "    'num_detector_pixels': n_dets_pcct_adv,\n",
    "    'energy_bins_keV': energy_bins_pcct_adv,\n",
    "    'source_photons_per_bin': I0_pcct_adv,\n",
    "    'energy_scaling_factors': energy_scales_pcct_adv,\n",
    "    'add_poisson_noise': False,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "pcct_ideal = PCCTProjectorOperator(**adv_effect_config)\n",
    "ideal_counts = pcct_ideal.op(true_mu_map_pcct_adv)\n",
    "\n",
    "pileup_demo_params = {'method': 'paralyzable', 'dead_time_s': 300e-9, 'acquisition_time_s': 1e-3}\n",
    "pcct_with_effects = PCCTProjectorOperator(\n",
    "    **adv_effect_config,\n",
    "    spectral_resolution_keV=15.0, \n",
    "    pileup_parameters=pileup_demo_params\n",
    ")\n",
    "counts_with_effects = pcct_with_effects.op(true_mu_map_pcct_adv)\n",
    "\n",
    "print(f\"Ideal total counts: {torch.sum(ideal_counts).item():.2e}\")\n",
    "print(f\"With effects total counts: {torch.sum(counts_with_effects).item():.2e}\")\n",
    "\n",
    "angle_idx_profile = n_angles_pcct_adv // 2\n",
    "bin_idx_profile = 1 # Middle bin\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ideal_counts[bin_idx_profile, angle_idx_profile, :].cpu().numpy(), label='Ideal Detector')\n",
    "plt.plot(counts_with_effects[bin_idx_profile, angle_idx_profile, :].cpu().numpy(), label='With Spectral Broadening & Pile-up', linestyle='--')\n",
    "plt.title(f'PCCT Sinogram Profile (Bin {bin_idx_profile}, Angle {angle_idx_profile})')\n",
    "plt.xlabel('Detector Pixel'); plt.ylabel('Photon Counts'); plt.legend(); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Projection-Domain Material Decomposition (Dual-Energy Example)\n",
    "This method solves a per-ray 2x2 system for material thicknesses, then reconstructs these thickness sinograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s_proj_decomp = (32, 32)\n",
    "n_angles_proj_decomp = 50\n",
    "n_dets_proj_decomp = int(np.floor(img_s_proj_decomp[0] * np.sqrt(2)) + 3) # Ensure it's a bit larger for placeholder radon\n",
    "if n_dets_proj_decomp % 2 == 0: n_dets_proj_decomp +=1\n",
    "\n",
    "true_material_A_map = torch.zeros(img_s_proj_decomp, device=device, dtype=torch.float32)\n",
    "true_material_A_map[8:24, 8:24] = 1.5 \n",
    "true_material_B_map = torch.zeros(img_s_proj_decomp, device=device, dtype=torch.float32)\n",
    "center_y_b, center_x_b = img_s_proj_decomp[0]//2, img_s_proj_decomp[1]//2\n",
    "radius_b = img_s_proj_decomp[0]//5\n",
    "yy_b, xx_b = torch.meshgrid(torch.arange(img_s_proj_decomp[0], device=device), torch.arange(img_s_proj_decomp[1], device=device), indexing='ij')\n",
    "mask_circle_b = (xx_b - center_x_b)**2 + (yy_b - center_y_b)**2 < radius_b**2\n",
    "true_material_B_map[mask_circle_b] = 2.0\n",
    "\n",
    "mac_A_bin1, mac_A_bin2 = 0.25, 0.15\n",
    "mac_B_bin1, mac_B_bin2 = 0.18, 0.22\n",
    "mac_matrix_proj_decomp = torch.tensor([[mac_A_bin1, mac_B_bin1], [mac_A_bin2, mac_B_bin2]], device=device, dtype=torch.float32)\n",
    "\n",
    "radon_op_notebook = LinearRadonOperatorPlaceholder(img_s_proj_decomp, n_angles_proj_decomp, n_dets_proj_decomp, str(device))\n",
    "\n",
    "tA_sino_true = radon_op_notebook.op(true_material_A_map)\n",
    "tB_sino_true = radon_op_notebook.op(true_material_B_map)\n",
    "L1_sino_true = mac_A_bin1 * tA_sino_true + mac_B_bin1 * tB_sino_true\n",
    "L2_sino_true = mac_A_bin2 * tA_sino_true + mac_B_bin2 * tB_sino_true\n",
    "log_sinos_for_decomp = torch.stack([L1_sino_true, L2_sino_true], dim=0)\n",
    "\n",
    "thickness_sinos = calculate_material_thickness_sinograms(log_sinos_for_decomp, mac_matrix_proj_decomp)\n",
    "print(f\"Calculated thickness sinograms shape: {thickness_sinos.shape}\")\n",
    "\n",
    "recon_thickness_maps = reconstruct_thickness_maps_from_sinograms(\n",
    "    thickness_sinograms=thickness_sinos,\n",
    "    radon_transform_operator=radon_op_notebook,\n",
    "    image_shape=img_s_proj_decomp,\n",
    "    iterations=30, step_size=5e-3, enforce_non_negativity=True, verbose=False\n",
    ")\n",
    "print(f\"Reconstructed thickness maps stack shape: {recon_thickness_maps.shape}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "vm_a = torch.max(true_material_A_map).item() if true_material_A_map.max() > 0 else 1.0\n",
    "vm_b = torch.max(true_material_B_map).item() if true_material_B_map.max() > 0 else 1.0\n",
    "im = axes[0,0].imshow(true_material_A_map.cpu().numpy(), cmap='viridis', vmin=0, vmax=vm_a); axes[0,0].set_title('True Material A'); fig.colorbar(im, ax=axes[0,0])\n",
    "im = axes[0,1].imshow(recon_thickness_maps[0].cpu().detach().numpy(), cmap='viridis', vmin=0, vmax=vm_a); axes[0,1].set_title('Recon Material A'); fig.colorbar(im, ax=axes[0,1])\n",
    "im = axes[1,0].imshow(true_material_B_map.cpu().numpy(), cmap='viridis', vmin=0, vmax=vm_b); axes[1,0].set_title('True Material B'); fig.colorbar(im, ax=axes[1,0])\n",
    "im = axes[1,1].imshow(recon_thickness_maps[1].cpu().detach().numpy(), cmap='viridis', vmin=0, vmax=vm_b); axes[1,1].set_title('Recon Material B'); fig.colorbar(im, ax=axes[1,1])\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Statistical Image Reconstruction (SIR) for $\\mu_{ref}$ (Poisson Likelihood)\n",
    "Demonstrates `tv_reconstruction_pcct_mu_ref` with `data_fidelity_mode='poisson_likelihood'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using common PCCT setup from Section 1 & 2 (true_mu_reference_map, energy_bins etc.)\n",
    "pcct_op_for_sir_recon = PCCTProjectorOperator(\n",
    "    image_shape=image_shape_pcct,\n",
    "    num_angles=num_angles_pcct,\n",
    "    num_detector_pixels=num_detector_pixels_pcct,\n",
    "    energy_bins_keV=energy_bins,\n",
    "    source_photons_per_bin=source_photons_I0,\n",
    "    energy_scaling_factors=energy_scaling,\n",
    "    add_poisson_noise=False, # Projector for model-based recon should be deterministic\n",
    "    device=device\n",
    ")\n",
    "\n",
    "mean_counts_for_sir = pcct_op_for_sir_recon.op(true_mu_reference_map)\n",
    "noisy_counts_for_sir = torch.poisson(torch.clamp(mean_counts_for_sir, min=0.0))\n",
    "\n",
    "lambda_tv_sir = 1e-5 \n",
    "iterations_sir = 30 \n",
    "step_size_sir = 1e-7 # Poisson grads can be large, often need smaller step size\n",
    "\n",
    "reconstructed_mu_ref_sir = tv_reconstruction_pcct_mu_ref(\n",
    "    y_photon_counts_stack=noisy_counts_for_sir,\n",
    "    pcct_operator=pcct_op_for_sir_recon,\n",
    "    lambda_tv=lambda_tv_sir,\n",
    "    iterations=iterations_sir,\n",
    "    step_size=step_size_sir,\n",
    "    verbose=True,\n",
    "    data_fidelity_mode='poisson_likelihood'\n",
    ")\n",
    "\n",
    "# For comparison, use the L2 result from cell for section 3a (reconstructed_mu_ref_global)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "max_val = true_mu_reference_map.max().cpu().item() * 1.1\n",
    "min_val = true_mu_reference_map.min().cpu().item()\n",
    "im1 = axes[0].imshow(true_mu_reference_map.cpu().numpy(), cmap='viridis', vmin=min_val, vmax=max_val); axes[0].set_title('True $\mu_{ref}$ Map'); fig.colorbar(im1, ax=axes[0])\n",
    "im2 = axes[1].imshow(reconstructed_mu_ref_global.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val); axes[1].set_title('L2 Recon.'); fig.colorbar(im2, ax=axes[1])\n",
    "im3 = axes[2].imshow(reconstructed_mu_ref_sir.cpu().detach().numpy(), cmap='viridis', vmin=min_val, vmax=max_val); axes[2].set_title('SIR (Poisson) Recon.'); fig.colorbar(im3, ax=axes[2])\n",
    "plt.suptitle('Comparison of L2 vs. Poisson Likelihood for $\mu_{ref}$ Reconstruction'); plt.tight_layout(rect=[0,0,1,0.95]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Iterative Material Decomposition (Image Domain)\n",
    "This section outlines using `IterativeMaterialDecompositionReconstructor`. The K-Edge demo from Python tests provides a good example structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for K-Edge like scenario (3 materials)\n",
    "img_s_kedge_nb = (32, 32) \n",
    "energy_bins_keV_kedge_nb = [(30.0, 48.0), (48.0, 52.0), (52.0, 70.0)] \n",
    "num_bins_kedge_nb = len(energy_bins_keV_kedge_nb)\n",
    "energy_scaling_factors_kedge_nb = torch.tensor([1.2, 1.0, 0.8], device=device, dtype=torch.float32) \n",
    "source_photons_per_bin_kedge_nb = torch.tensor([1e5] * num_bins_kedge_nb, device=device, dtype=torch.float32)\n",
    "\n",
    "pcct_op_kedge_nb = PCCTProjectorOperator(\n",
    "    image_shape=img_s_kedge_nb, \n",
    "    num_angles=30, # Reduced for speed in notebook \n",
    "    num_detector_pixels=35, # Odd number\n",
    "    energy_bins_keV=energy_bins_keV_kedge_nb, \n",
    "    source_photons_per_bin=source_photons_per_bin_kedge_nb,   \n",
    "    energy_scaling_factors=energy_scaling_factors_kedge_nb, \n",
    "    device=device,\n",
    "    add_poisson_noise=False # For cleaner data for decomposition demo\n",
    ")\n",
    "\n",
    "mat_ref_att_kedge_nb = {'water': 0.20, 'soft_tissue': 0.19, 'contrast_agent': 0.80}\n",
    "basis_names_kedge_nb = ['water', 'soft_tissue', 'contrast_agent']\n",
    "\n",
    "mat_decomp_op_kedge_nb = MaterialDecompositionForwardOperator(\n",
    "    material_reference_attenuations=mat_ref_att_kedge_nb,\n",
    "    pcct_projector=pcct_op_kedge_nb,\n",
    "    basis_material_names=basis_names_kedge_nb,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "true_basis_kedge_nb = torch.zeros(len(basis_names_kedge_nb), *img_s_kedge_nb, device=device, dtype=torch.float32)\n",
    "h_k, w_k = img_s_kedge_nb\n",
    "true_basis_kedge_nb[0, :, :] = 1.0 # Water background\n",
    "true_basis_kedge_nb[1, h_k//4:h_k*3//4, w_k//4:w_k*3//4] = 0.7; true_basis_kedge_nb[0, h_k//4:h_k*3//4, w_k//4:w_k*3//4] -= 0.7\n",
    "yy_k, xx_k = torch.meshgrid(torch.arange(h_k, device=device), torch.arange(w_k, device=device), indexing='ij')\n",
    "mask_ca = (xx_k - w_k//2)**2 + (yy_k - h_k//2)**2 < (h_k//6)**2\n",
    "true_basis_kedge_nb[2, mask_ca] = 0.5; true_basis_kedge_nb[1, mask_ca] -= 0.5\n",
    "true_basis_kedge_nb = torch.clamp(true_basis_kedge_nb, min=0.0)\n",
    "\n",
    "measured_sinos_kedge_nb = mat_decomp_op_kedge_nb.op(true_basis_kedge_nb)\n",
    "\n",
    "recon_kedge = IterativeMaterialDecompositionReconstructor(\n",
    "    iterations=30, step_size=1e-6, enforce_non_negativity=True, verbose=False\n",
    ")\n",
    "initial_guess_kedge_nb = torch.clamp(mat_decomp_op_kedge_nb.op_adj(measured_sinos_kedge_nb), min=0.0)\n",
    "\n",
    "recons_basis_kedge_nb = recon_kedge.reconstruct(measured_sinos_kedge_nb, mat_decomp_op_kedge_nb, initial_guess_kedge_nb)\n",
    "\n",
    "fig, axes = plt.subplots(len(basis_names_kedge_nb), 2, figsize=(8, 4*len(basis_names_kedge_nb)))\n",
    "for i, name in enumerate(basis_names_kedge_nb):\n",
    "    vm = true_basis_kedge_nb[i].max().item() if true_basis_kedge_nb[i].max() > 0 else 1.0\n",
    "    ax_true = axes[i,0] if len(basis_names_kedge_nb) > 1 else axes[0]\n",
    "    im_t = ax_true.imshow(true_basis_kedge_nb[i].cpu().numpy(), cmap='viridis', vmin=0, vmax=vm); fig.colorbar(im_t, ax=ax_true); ax_true.set_title(f'True {name}')\n",
    "    ax_recon = axes[i,1] if len(basis_names_kedge_nb) > 1 else axes[1]\n",
    "    im_r = ax_recon.imshow(recons_basis_kedge_nb[i].cpu().detach().numpy(), cmap='viridis', vmin=0, vmax=vm); fig.colorbar(im_r, ax=ax_recon); ax_recon.set_title(f'Recon {name}')\n",
    "plt.suptitle('Iterative Material Decomposition (K-Edge Demo)')\n",
    "plt.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** The placeholder Radon/Back-projection and the simplified energy dependence make this demo highly illustrative. The reconstruction quality will be limited. For actual PCCT, advanced operators (accurate Radon, physics-based spectral modeling) and reconstructors (e.g., statistical iterative methods that handle Poisson noise, material decomposition algorithms) are necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"  // Updated to reflect typical environment
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
