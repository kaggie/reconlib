{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Guide: Basic Non-Cartesian Reconstruction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial guides you through setting up and running a simple end-to-end 2D non-Cartesian MRI reconstruction pipeline using the `reconlib` library. We will cover the essential steps from simulating k-space data to reconstructing an image using a NUFFT operator and an iterative solver.\n",
    "\n",
    "**Steps Covered:**\n",
    "1. Setup and necessary imports.\n",
    "2. Generation of a phantom and a non-Cartesian (radial) k-space trajectory.\n",
    "3. Simulation of k-space data, including adding noise.\n",
    "4. Configuration and instantiation of the NUFFT (Non-Uniform Fast Fourier Transform) operator.\n",
    "5. Performing image reconstruction using the Conjugate Gradient solver.\n",
    "6. Visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ReconLib imports\n",
    "try:\n",
    "    from reconlib.nufft import NUFFT2D\n",
    "    from reconlib.solvers import conjugate_gradient_reconstruction\n",
    "    # For data simulation - assuming functions from iternufft.py are suitable\n",
    "    # These were identified during the creation of voronoi_recon_comparison.ipynb\n",
    "    from iternufft import generate_phantom_2d, generate_radial_trajectory_2d\n",
    "    print(\"Successfully imported reconlib components and simulation utilities.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Please ensure reconlib is installed and iternufft.py is in the Python path.\")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "First, we'll define the parameters for our simulation, generate a simple 2D phantom, create a radial k-space trajectory, and then simulate the k-space data by applying the forward NUFFT operation. Finally, we'll add some noise to make the reconstruction task more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "IMAGE_SIZE = 128       # Size of the image (NxN)\n",
    "N_SPOKES = 128         # Number of radial spokes in k-space\n",
    "N_SAMPLES_PER_SPOKE = int(IMAGE_SIZE * 1.5) # Number of samples along each spoke (oversampling factor of 1.5 along readout)\n",
    "NOISE_STD_PERCENT = 0.02 # Noise level as a percentage of max k-space signal\n",
    "\n",
    "# --- Generate Phantom ---\n",
    "try:\n",
    "    phantom_img = generate_phantom_2d(size=IMAGE_SIZE, device=device)\n",
    "    phantom_complex = phantom_img.to(torch.complex64)\n",
    "    print(f\"Phantom generated with shape: {phantom_img.shape}\")\n",
    "except NameError:\n",
    "    print(\"generate_phantom_2d not available. Using a placeholder.\")\n",
    "    phantom_complex = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(phantom_complex.abs().cpu().numpy(), cmap='gray')\n",
    "plt.title(f\"Original Phantom ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# --- Generate K-Space Trajectory ---\n",
    "try:\n",
    "    k_trajectory = generate_radial_trajectory_2d(\n",
    "        num_spokes=N_SPOKES,\n",
    "        samples_per_spoke=N_SAMPLES_PER_SPOKE,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"K-space trajectory generated. Shape: {k_trajectory.shape}\")\n",
    "except NameError:\n",
    "    print(\"generate_radial_trajectory_2d not available. Using placeholder.\")\n",
    "    k_trajectory = torch.rand((N_SPOKES * N_SAMPLES_PER_SPOKE, 2), device=device) - 0.5\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(k_trajectory[:, 0].cpu().numpy(), k_trajectory[:, 1].cpu().numpy(), s=0.5)\n",
    "plt.title(f\"K-Space Trajectory\")\n",
    "plt.xlabel(\"kx\"); plt.ylabel(\"ky\")\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate K-Space Data and Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate K-Space Data (Forward NUFFT) ---\n",
    "# First, we need a NUFFT operator for the forward simulation.\n",
    "# We'll use default parameters for NUFFT2D for simplicity here.\n",
    "# These parameters should be suitable for the k_trajectory and phantom_complex defined earlier.\n",
    "# No explicit density compensation is typically used for the forward model.\n",
    "\n",
    "try:\n",
    "    nufft_params_sim = {\n",
    "        'image_shape': (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        'k_trajectory': k_trajectory,\n",
    "        'oversamp_factor': (2.0, 2.0), \n",
    "        'kb_J': (4, 4),      \n",
    "        'kb_alpha': (2.34 * 4, 2.34 * 4), \n",
    "        'Ld': (1024, 1024), \n",
    "        'kb_m': (0.0, 0.0),       \n",
    "        'device': device\n",
    "    }\n",
    "    nufft_op_sim = NUFFT2D(**nufft_params_sim)\n",
    "    print(\"NUFFT operator for simulation created.\")\n",
    "\n",
    "    k_space_data_clean = nufft_op_sim.forward(phantom_complex)\n",
    "    print(f\"Clean k-space data simulated. Shape: {k_space_data_clean.shape}\")\n",
    "\n",
    "    # --- Add Complex Gaussian Noise ---\n",
    "    noise_std_val = NOISE_STD_PERCENT * torch.max(torch.abs(k_space_data_clean))\n",
    "    \n",
    "    # Generate noise for real and imaginary parts separately then combine\n",
    "    noise_real_part = torch.randn_like(k_space_data_clean.real) * noise_std_val\n",
    "    noise_imag_part = torch.randn_like(k_space_data_clean.imag) * noise_std_val\n",
    "    complex_noise = torch.complex(noise_real_part, noise_imag_part).to(device)\n",
    "    \n",
    "    k_space_data_noisy = k_space_data_clean + complex_noise\n",
    "    print(f\"Noisy k-space data created. Shape: {k_space_data_noisy.shape}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"A required variable (IMAGE_SIZE, k_trajectory, device, phantom_complex, NOISE_STD_PERCENT, NUFFT2D) is not defined: {e}\")\n",
    "    print(\"Please ensure the previous cells have been run.\")\n",
    "    k_space_data_noisy = torch.zeros((k_trajectory.shape[0] if 'k_trajectory' in globals() else 1), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"Error during k-space simulation or noise addition: {e}\")\n",
    "    k_space_data_noisy = torch.zeros((k_trajectory.shape[0] if 'k_trajectory' in globals() else 1), dtype=torch.complex64, device=device) # Placeholder\n",
    "\n",
    "\n",
    "# --- Visualize K-Space (Magnitude) ---\n",
    "plt.figure(figsize=(5,5))\n",
    "if 'k_space_data_noisy' in globals() and k_space_data_noisy.numel() > 0 :\n",
    "    plt.scatter(k_trajectory[:,0].cpu(), k_trajectory[:,1].cpu(), \n",
    "                c=torch.log(torch.abs(k_space_data_noisy.cpu()) + 1e-9), # log scale for better viz\n",
    "                s=1, cmap='viridis')\n",
    "    plt.colorbar(label=\"log|k-space data|\")\n",
    "else:\n",
    "    plt.text(0.5,0.5, \"K-space data not available\", ha='center', va='center')\n",
    "plt.title(\"Simulated Noisy K-Space Data (Log Magnitude)\")\n",
    "plt.xlabel(\"kx\"); plt.ylabel(\"ky\")\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NUFFT Operator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NUFFT Operator Setup for Reconstruction ---\n",
    "# For reconstruction, we instantiate another NUFFT operator.\n",
    "# This operator will be used by the solver (e.g., Conjugate Gradient).\n",
    "# For this basic tutorial, we'll configure it similarly to the simulation NUFFT,\n",
    "# without explicitly passing density_comp_weights. The conjugate_gradient_reconstruction\n",
    "# solver itself will handle passing relevant parts of these nufft_kwargs to the\n",
    "# NUFFT2D constructor. If density_comp_weights were to be used (e.g. Voronoi),\n",
    "# they would be included in this nufft_kwargs dictionary.\n",
    "\n",
    "print(\"\\n--- Setting up NUFFT Operator for Reconstruction ---\")\n",
    "try:\n",
    "    # These parameters are largely the same as for the simulation NUFFT operator.\n",
    "    # The k_trajectory and image_shape must match the data we are reconstructing.\n",
    "    nufft_recon_kwargs = {\n",
    "        'oversamp_factor': (2.0, 2.0), \n",
    "        'kb_J': (4, 4),      \n",
    "        'kb_alpha': (2.34 * 4, 2.34 * 4), \n",
    "        'Ld': (1024, 1024), \n",
    "        'kb_m': (0.0, 0.0)\n",
    "        # device, image_shape, k_trajectory will be passed by the solver\n",
    "        # or when NUFFT2D is directly instantiated with all args.\n",
    "        # For clarity here, we are defining the 'kwargs' part that the solver would use.\n",
    "        # No 'density_comp_weights' are specified here for the most basic case.\n",
    "        # The solver (e.g. conjugate_gradient_reconstruction) will instantiate\n",
    "        # NUFFT2D using these kwargs along with image_shape, k_trajectory, and device.\n",
    "    }\n",
    "    \n",
    "    # We can also instantiate it directly for clarity or if we wanted to perform\n",
    "    # a simple adjoint reconstruction manually (though solvers handle this).\n",
    "    nufft_op_recon_direct_instance = NUFFT2D(\n",
    "        image_shape=(IMAGE_SIZE, IMAGE_SIZE), # from previous cell\n",
    "        k_trajectory=k_trajectory,          # from previous cell\n",
    "        device=device,                      # from previous cell\n",
    "        **nufft_recon_kwargs\n",
    "    )\n",
    "    print(f\"NUFFT2D operator for reconstruction purposes configured (can be instantiated by solver or directly).\")\n",
    "    print(f\"Using parameters: image_shape={(IMAGE_SIZE,IMAGE_SIZE)}, os_factor={nufft_recon_kwargs['oversamp_factor']}, J={nufft_recon_kwargs['kb_J']}\")\n",
    "    if hasattr(nufft_op_recon_direct_instance, 'density_comp_weights') and nufft_op_recon_direct_instance.density_comp_weights is not None:\n",
    "        print(f\"NUFFT op has density_comp_weights of shape: {nufft_op_recon_direct_instance.density_comp_weights.shape}\")\n",
    "    else:\n",
    "        print(\"NUFFT op configured without explicit external density_comp_weights (will use internal default if any).\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"A required variable (IMAGE_SIZE, k_trajectory, device, NUFFT2D) is not defined: {e}\")\n",
    "    print(\"Please ensure the previous cells have been run.\")\n",
    "    nufft_recon_kwargs = {} # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up NUFFT reconstruction operator: {e}\")\n",
    "    nufft_recon_kwargs = {} # Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perform Image Reconstruction using Conjugate Gradient ---\n",
    "# We'll use the `conjugate_gradient_reconstruction` solver from `reconlib.solvers`.\n",
    "# This solver iteratively finds an image that best fits the k-space data\n",
    "# according to the normal equations (A^H A x = A^H y), where A is the NUFFT operator.\n",
    "\n",
    "print(\"\\n--- Performing Image Reconstruction ---\")\n",
    "\n",
    "# Reconstruction parameters\n",
    "CG_ITERS = 20  # Number of Conjugate Gradient iterations\n",
    "CG_TOL = 1e-6  # Tolerance for convergence\n",
    "\n",
    "try:\n",
    "    # Ensure necessary variables from previous cells are available\n",
    "    if 'k_space_data_noisy' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals() or \\\n",
    "       'k_trajectory' not in globals() or \\\n",
    "       'device' not in globals() or \\\n",
    "       'nufft_recon_kwargs' not in globals() or \\\n",
    "       'NUFFT2D' not in globals() or \\\n",
    "       'conjugate_gradient_reconstruction' not in globals():\n",
    "        raise NameError(\"One or more required variables/functions are not defined. Please run previous cells.\")\n",
    "\n",
    "    print(f\"Starting Conjugate Gradient reconstruction (iters={CG_ITERS}, tol={CG_TOL:.1e})...\")\n",
    "    \n",
    "    # The solver will internally instantiate NUFFT2D using image_shape, k_trajectory,\n",
    "    # device, and the **nufft_recon_kwargs.\n",
    "    recon_image_cg = conjugate_gradient_reconstruction(\n",
    "        kspace_data=k_space_data_noisy,\n",
    "        sampling_points=k_trajectory, # Passed directly to NUFFT op via solver\n",
    "        image_shape=(IMAGE_SIZE, IMAGE_SIZE), # Passed directly to NUFFT op via solver\n",
    "        nufft_operator_class=NUFFT2D,     # The NUFFT class to use\n",
    "        nufft_kwargs=nufft_recon_kwargs,  # Dictionary of other NUFFT params\n",
    "        max_iters=CG_ITERS,\n",
    "        tol=CG_TOL\n",
    "        # For this basic tutorial, use_voronoi is False (default) and\n",
    "        # no explicit voronoi_weights are passed. The NUFFT operator will use\n",
    "        # its internal default DCF if density_comp_weights was not in nufft_recon_kwargs.\n",
    "    )\n",
    "    \n",
    "    print(\"Conjugate Gradient reconstruction complete.\")\n",
    "    print(f\"Reconstructed image shape: {recon_image_cg.shape}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Could not perform reconstruction.\")\n",
    "    recon_image_cg = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during CG reconstruction: {e}\")\n",
    "    recon_image_cg = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.complex64, device=device) # Placeholder\n",
    "\n",
    "# The reconstructed image `recon_image_cg` will be visualized in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize the Reconstructed Image ---\n",
    "print(\"\\n--- Visualizing Final Reconstructed Image ---\")\n",
    "\n",
    "try:\n",
    "    if 'recon_image_cg' not in globals() or \\\n",
    "       'phantom_complex' not in globals() or \\\n",
    "       'IMAGE_SIZE' not in globals():\n",
    "        raise NameError(\"Required variables (recon_image_cg, phantom_complex, IMAGE_SIZE) not found. Run previous cells.\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Original Phantom\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(phantom_complex.abs().cpu().numpy(), cmap='gray')\n",
    "    plt.title(f\"Original Phantom ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed Image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(torch.abs(recon_image_cg.cpu()).numpy(), cmap='gray')\n",
    "    plt.title(f\"Reconstructed Image (CG, {CG_ITERS} iters)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Optional: Calculate and print some metrics\n",
    "    try:\n",
    "        from reconlib.metrics.image_metrics import mse, psnr, ssim\n",
    "        \n",
    "        original_abs = phantom_complex.abs().cpu()\n",
    "        recon_abs = torch.abs(recon_image_cg.cpu())\n",
    "        data_range_val = original_abs.max() - original_abs.min()\n",
    "        if data_range_val == 0: data_range_val = 1.0\n",
    "\n",
    "        mse_val = mse(original_abs, recon_abs).item()\n",
    "        psnr_val = psnr(original_abs, recon_abs, data_range=data_range_val).item()\n",
    "        # Add batch and channel dims for SSIM: (B, C, H, W)\n",
    "        ssim_val = ssim(original_abs.unsqueeze(0).unsqueeze(0), \n",
    "                        recon_abs.unsqueeze(0).unsqueeze(0), \n",
    "                        data_range=data_range_val,\n",
    "                        gaussian_kernel=True, kernel_size=7).item()\n",
    "                        \n",
    "        print(\"\\n--- Reconstruction Metrics ---\")\n",
    "        print(f\"MSE: {mse_val:.4e}\")\n",
    "        print(f\"PSNR: {psnr_val:.2f} dB\")\n",
    "        print(f\"SSIM: {ssim_val:.4f}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"\\nSkipping metrics: reconlib.metrics.image_metrics not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Cannot visualize.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Next Steps\n",
    "\n",
    "This tutorial demonstrated a basic pipeline for non-Cartesian MRI reconstruction using `reconlib`. We covered:\n",
    "- Simulating a phantom and radial k-space data.\n",
    "- Setting up a `NUFFT2D` operator.\n",
    "- Reconstructing the image using the `conjugate_gradient_reconstruction` solver.\n",
    "- Visualizing the results.\n",
    "\n",
    "**Further Exploration:**\n",
    "- **Density Compensation:** The reconstruction above used the NUFFT operator's default density compensation (if any). For improved results, especially with non-uniform trajectories, explicit density compensation is crucial. You can explore using Voronoi-based DCF by:\n",
    "    1. Computing `voronoi_weights` (see `examples/voronoi_recon_comparison.ipynb`).\n",
    "    2. Passing these weights as `density_comp_weights` within the `nufft_kwargs` when calling the solver.\n",
    "- **Regularization:** To handle noise or undersampling artifacts better, you can incorporate regularizers (e.g., L1, Total Variation) using solvers like `fista_reconstruction` or `admm_reconstruction`. See the planned `tutorial_regularizers.ipynb` for examples.\n",
    "- **Different Trajectories:** Experiment with other k-space trajectories (e.g., spiral).\n",
    "- **3D Reconstruction:** Extend these concepts to 3D using `NUFFT3D`.\n",
    "\n",
    "This notebook provides a starting point. The `reconlib` library offers many components to build more sophisticated reconstruction pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
